{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Numenta Platform for Intelligent Computing (NuPIC)\n",
    "# Copyright (C) 2019, Numenta, Inc.  Unless you have an agreement\n",
    "# with Numenta, Inc., for a separate license for this software code, the\n",
    "# following terms and conditions apply:\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Affero Public License version 3 as\n",
    "# published by the Free Software Foundation.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
    "# See the GNU Affero Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU Affero Public License\n",
    "# along with this program.  If not, see http://www.gnu.org/licenses.\n",
    "#\n",
    "# http://numenta.org/licenses/\n",
    "# ----------------------------------------------------------------------\n",
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import k_winners_base as F\n",
    "from duty_cycle_metrics import binary_entropy, max_entropy\n",
    "\n",
    "\n",
    "def update_boost_strength(m):\n",
    "    \"\"\"Function used to update KWinner modules boost strength after each epoch.\n",
    "\n",
    "    Call using :meth:`torch.nn.Module.apply` after each epoch if required\n",
    "    For example: ``m.apply(update_boost_strength)``\n",
    "\n",
    "    :param m: KWinner module\n",
    "    \"\"\"\n",
    "    if isinstance(m, KWinnersBase):\n",
    "        m.update_boost_strength()\n",
    "\n",
    "\n",
    "class KWinnersBase(nn.Module, metaclass=abc.ABCMeta):\n",
    "    def __init__(\n",
    "        self,\n",
    "        percent_on,\n",
    "        k_inference_factor=1.0,\n",
    "        boost_strength=1.0,\n",
    "        boost_strength_factor=1.0,\n",
    "        duty_cycle_period=1000,\n",
    "    ):\n",
    "        \"\"\"Base KWinners class.\n",
    "\n",
    "        :param percent_on:\n",
    "          The activity of the top k = percent_on * number of input units will be\n",
    "          allowed to remain, the rest are set to zero.\n",
    "        :type percent_on: float\n",
    "\n",
    "        :param k_inference_factor:\n",
    "          During inference (training=False) we increase percent_on by this factor.\n",
    "          percent_on * k_inference_factor must be strictly less than 1.0, ideally much\n",
    "          lower than 1.0\n",
    "        :type k_inference_factor: float\n",
    "\n",
    "        :param boost_strength:\n",
    "          boost strength (0.0 implies no boosting). Must be >= 0.0\n",
    "        :type boost_strength: float\n",
    "\n",
    "        :param boost_strength_factor:\n",
    "          Boost strength factor to use [0..1]\n",
    "        :type boost_strength_factor: float\n",
    "\n",
    "        :param duty_cycle_period:\n",
    "          The period used to calculate duty cycles\n",
    "        :type duty_cycle_period: int\n",
    "        \"\"\"\n",
    "        super(KWinnersBase, self).__init__()\n",
    "        assert boost_strength >= 0.0\n",
    "        assert 0.0 <= boost_strength_factor <= 1.0\n",
    "        assert 0.0 < percent_on < 1.0\n",
    "        assert 0.0 < percent_on * k_inference_factor < 1.0\n",
    "\n",
    "        self.percent_on = percent_on\n",
    "        self.percent_on_inference = percent_on * k_inference_factor\n",
    "        self.k_inference_factor = k_inference_factor\n",
    "        self.learning_iterations = 0\n",
    "        self.n = 0\n",
    "        self.k = 0\n",
    "        self.k_inference = 0\n",
    "\n",
    "        # Boosting related parameters\n",
    "        self.boost_strength = boost_strength\n",
    "        self.boost_strength_factor = boost_strength_factor\n",
    "        self.duty_cycle_period = duty_cycle_period\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            \"n={0}, percent_on={1}, boost_strength={2}, boost_strength_factor={3}, \"\n",
    "            \"k_inference_factor={4}, duty_cycle_period={5}\".format(\n",
    "                self.n,\n",
    "                self.percent_on,\n",
    "                self.boost_strength,\n",
    "                self.boost_strength_factor,\n",
    "                self.k_inference_factor,\n",
    "                self.duty_cycle_period,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_duty_cycle(self, x):\n",
    "        r\"\"\"Updates our duty cycle estimates with the new value. Duty cycles are\n",
    "        updated according to the following formula:\n",
    "\n",
    "        .. math::\n",
    "            dutyCycle = \\frac{dutyCycle \\times \\left( period - batchSize \\right)\n",
    "                                + newValue}{period}\n",
    "\n",
    "        :param x:\n",
    "          Current activity of each unit\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_boost_strength(self):\n",
    "        \"\"\"Update boost strength using given strength factor during\n",
    "        training.\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self.boost_strength = self.boost_strength * self.boost_strength_factor\n",
    "\n",
    "    def entropy(self):\n",
    "        \"\"\"Returns the current total entropy of this layer.\"\"\"\n",
    "        _, entropy = binary_entropy(self.duty_cycle)\n",
    "        return entropy\n",
    "\n",
    "    def max_entropy(self):\n",
    "        \"\"\"Returns the maximum total entropy we can expect from this layer.\"\"\"\n",
    "        return max_entropy(self.n, int(self.n * self.percent_on))\n",
    "\n",
    "\n",
    "class KWinners(KWinnersBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n,\n",
    "        percent_on,\n",
    "        k_inference_factor=1.5,\n",
    "        stoch_sd=0.0,\n",
    "        boost_strength=1.0,\n",
    "        boost_strength_factor=0.9,\n",
    "        duty_cycle_period=1000,\n",
    "    ):\n",
    "        \"\"\"Applies K-Winner function to the input tensor.\n",
    "\n",
    "        See :class:`htmresearch.frameworks.pytorch.functions.k_winners`\n",
    "        :param n:\n",
    "          Number of units\n",
    "        :type n: int\n",
    "\n",
    "        :param percent_on:\n",
    "          The activity of the top k = percent_on * n will be allowed to remain, the\n",
    "          rest are set to zero.\n",
    "        :type percent_on: float\n",
    "\n",
    "        :param k_inference_factor:\n",
    "          During inference (training=False) we increase percent_on by this factor.\n",
    "          percent_on * k_inference_factor must be strictly less than 1.0, ideally much\n",
    "          lower than 1.0\n",
    "        :type k_inference_factor: float\n",
    "\n",
    "        :param boost_strength:\n",
    "          boost strength (0.0 implies no boosting).\n",
    "        :type boost_strength: float\n",
    "\n",
    "        :param boost_strength_factor:\n",
    "          Boost strength factor to use [0..1]\n",
    "        :type boost_strength_factor: float\n",
    "\n",
    "        :param duty_cycle_period:\n",
    "          The period used to calculate duty cycles\n",
    "        :type duty_cycle_period: int\n",
    "        \"\"\"\n",
    "        super(KWinners, self).__init__(\n",
    "            percent_on=percent_on,\n",
    "            k_inference_factor=k_inference_factor,\n",
    "            boost_strength=boost_strength,\n",
    "            boost_strength_factor=boost_strength_factor,\n",
    "            duty_cycle_period=duty_cycle_period,\n",
    "        )\n",
    "        self.n = n\n",
    "        self.k = int(round(n * percent_on))\n",
    "        self.k_inference = int(self.k * self.k_inference_factor)\n",
    "        self.stoch_sd = stoch_sd\n",
    "        self.register_buffer(\"duty_cycle\", torch.zeros(self.n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stoch_sd:\n",
    "            k = int(np.random.normal(self.k, self.stoch_sd))\n",
    "        else:\n",
    "            k = self.k\n",
    "        if self.training:\n",
    "\n",
    "            x = F.KWinners.apply(x, self.duty_cycle, k, self.boost_strength)\n",
    "\n",
    "            self.update_duty_cycle(x)\n",
    "        else:\n",
    "            x = F.KWinners.apply(\n",
    "                x,\n",
    "                self.duty_cycle,\n",
    "                int(k * self.k_inference_factor),\n",
    "                self.boost_strength,\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def update_duty_cycle(self, x):\n",
    "\n",
    "        batch_size = x.shape[0]      \n",
    "        self.learning_iterations += batch_size\n",
    "        period = min(self.duty_cycle_period, self.learning_iterations)\n",
    "        self.duty_cycle.mul_(period - batch_size)\n",
    "        self.duty_cycle.add_(x.gt(0).sum(dim=0, dtype=torch.float)) # added [0,0,:] to x\n",
    "        self.duty_cycle.div_(period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from active_dendrite import ActiveDendriteLayer\n",
    "# from nupic.torch.modules.k_winners import KWinners\n",
    "from k_winners import KWinners\n",
    "from sparse_weights import SparseWeights\n",
    "from util import activity_square, count_parameters, get_grad_printer\n",
    "\n",
    "\n",
    "def topk_mask(x, k=2):\n",
    "    \"\"\"\n",
    "    Simple functional version of KWinnersMask/KWinners since\n",
    "    autograd function apparently not currently exportable by JIT\n",
    "    \"\"\"\n",
    "    res = torch.zeros_like(x)\n",
    "    topk, indices = x.topk(k, sorted=False)\n",
    "    return res.scatter(-1, indices, 1)\n",
    "\n",
    "\n",
    "class RSMPredictor(torch.nn.Module):\n",
    "    def __init__(self, d_in=28 * 28, d_out=10, hidden_size=20):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(RSMPredictor, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.d_in, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.d_out),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self._init_linear_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Receive input as hidden memory state from RSM, batch\n",
    "        x^B is with shape (batch_size, total_cells)\n",
    "        Output is two tensors of shape (batch_size, d_out) being distribution and\n",
    "        logits respectively.\n",
    "        \"\"\"\n",
    "\n",
    "        x1 = None\n",
    "        x2 = x\n",
    "        for layer in self.layers:\n",
    "            x1 = x2\n",
    "            x2 = layer(x1)\n",
    "\n",
    "        # Return multiple outputs\n",
    "        # https://discuss.pytorch.org/t/a-model-with-multiple-outputs/10440\n",
    "        logits = x1.view(-1, self.d_out)\n",
    "\n",
    "        distribution = x2.view(-1, self.d_out)\n",
    "        return distribution, logits\n",
    "\n",
    "    def _init_linear_weights(self):\n",
    "        for mod in self.modules():\n",
    "            if isinstance(mod, nn.Linear):\n",
    "                sd = 0.03\n",
    "                mod.weight.data.normal_(0.0, sd)\n",
    "                if mod.bias is not None:\n",
    "                    mod.bias.data.normal_(0.0, sd)\n",
    "\n",
    "\n",
    "class RSMNet(torch.nn.Module):\n",
    "    def __init__(self, n_layers=1, **kwargs):\n",
    "        super(RSMNet, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hooks_registered = False\n",
    "\n",
    "        eps_arr = self._parse_param_array(kwargs[\"eps\"])\n",
    "        k_winners_arr = self._parse_param_array(kwargs[\"k\"])\n",
    "        boost_strength_arr = self._parse_param_array(kwargs[\"boost_strength\"])\n",
    "        duty_cycle_period_arr = self._parse_param_array(\n",
    "            kwargs.get(\"duty_cycle_period\", 1000)\n",
    "        )\n",
    "        m_arr = self._parse_param_array(kwargs[\"m\"])\n",
    "        n_arr = self._parse_param_array(kwargs[\"n\"])\n",
    "        last_output_dim = None\n",
    "        self.total_cells = []\n",
    "        for i in range(n_layers):\n",
    "            first_layer = i == 0\n",
    "            top_layer = i == n_layers - 1\n",
    "            if not first_layer:\n",
    "                kwargs[\"d_in\"] = last_output_dim\n",
    "                # Output is of same dim as input (predictive autoencoder)\n",
    "                kwargs[\"d_out\"] = kwargs[\"d_in\"]\n",
    "            if not top_layer:\n",
    "                kwargs[\"d_above\"] = m_arr[i + 1] * n_arr[i + 1]\n",
    "            if kwargs.get(\"lateral_conn\", True):\n",
    "                if top_layer:\n",
    "                    kwargs[\"lateral_conn\"] = kwargs.get(\"top_lateral_conn\", False)\n",
    "            kwargs[\"eps\"] = eps_arr[i]\n",
    "            kwargs[\"m\"] = m_arr[i]\n",
    "            kwargs[\"n\"] = n_arr[i]\n",
    "            kwargs[\"k\"] = k_winners_arr[i]\n",
    "            kwargs[\"boost_strength\"] = boost_strength_arr[i]\n",
    "            kwargs[\"duty_cycle_period\"] = duty_cycle_period_arr[i]\n",
    "            self.total_cells.append(kwargs[\"m\"] * kwargs[\"n\"])\n",
    "            last_output_dim = kwargs[\"m\"] * kwargs[\"n\"]\n",
    "            self.add_module(\"RSM_%d\" % (i + 1), RSMLayer(**kwargs))\n",
    "\n",
    "        print(\"Created RSMNet with %d layer(s)\" % n_layers)\n",
    "\n",
    "    def _parse_param_array(self, param_val):\n",
    "        param_by_layer = param_val\n",
    "        if not isinstance(param_by_layer, list):\n",
    "            param_by_layer = [param_by_layer for x in range(self.n_layers)]\n",
    "        return param_by_layer\n",
    "\n",
    "    def _zero_sparse_weights(self):\n",
    "        for mod in self.children():\n",
    "            mod._zero_sparse_weights()\n",
    "\n",
    "    def _zero_kwinner_boost(self):\n",
    "        # Zero KWinner boost strengths since learning in RSM is pausing\n",
    "        for layer in self.children():\n",
    "            for mod in layer.children():\n",
    "                if isinstance(mod, KWinners) and mod.boost_strength_factor < 1.0:\n",
    "                    print(\"Zeroing boost strength for %s\" % mod)\n",
    "                    mod.boost_strength = 0.0\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        if not self.hooks_registered:\n",
    "            for mod in self.children():\n",
    "                mod._register_hooks()\n",
    "        self.hooks_registered = True\n",
    "\n",
    "    def forward(self, x_a_batch, hidden):\n",
    "        \"\"\"\n",
    "        Each layer takes input (image batch from time sequence for first layer,\n",
    "        batch of hidden states from prior layer otherwise), and generates both:\n",
    "            - a prediction for the next input it will see\n",
    "            - a hidden state which is passed to the next layer\n",
    "        Arguments:\n",
    "            x_a_batch: (bsz, d_in)\n",
    "            hidden: Tuple (x_b, phi, psi), each Tensor (n_layers, bsz, total_cells)\n",
    "                - x_b is (possibly normalized) winners without hysteresis/decayed memory\n",
    "        Returns:\n",
    "            output_by_layer: List of tensors\n",
    "                (n_layers, bsz, dim (total_cells or d_in for first layer))\n",
    "            new_hidden: Tuple of tensors (n_layers, bsz, total_cells)\n",
    "        \"\"\"\n",
    "        output_by_layer = []\n",
    "\n",
    "        new_x_b = []\n",
    "        new_phi = []\n",
    "        new_psi = []\n",
    "\n",
    "        x_b, phi, psi = hidden\n",
    "        layer_input = x_a_batch\n",
    "\n",
    "        lid = 0\n",
    "        for (_layer_name, layer), lay_phi, lay_psi in zip(\n",
    "            self.named_children(), phi, psi\n",
    "        ):\n",
    "            last_layer = lid == len(phi) - 1\n",
    "            lay_above = list(self.children())[lid + 1] if not last_layer else None\n",
    "            lay_x_b = x_b[lid]\n",
    "            lay_x_above = x_b[lid + 1] if not last_layer else None\n",
    "\n",
    "            # Update memory psi with prior step winners and apply decay as per config\n",
    "            if lay_x_above is not None:\n",
    "                psi_above = psi[lid + 1]\n",
    "                lay_x_above = lay_above._decay_memory(psi_above, lay_x_above)\n",
    "            if lay_x_b is not None:\n",
    "                lay_x_b = layer._decay_memory(lay_psi, lay_x_b)\n",
    "\n",
    "            hidden_in = (lay_x_b, lay_x_above, lay_phi, lay_psi)\n",
    "\n",
    "            pred_output, hidden = layer(layer_input, hidden_in)\n",
    "\n",
    "            # If layers > 1, higher layers predict lower layer's phi\n",
    "            # phi has hysteresis (if decay active), x_b is just winners\n",
    "            layer_input = hidden[1]  # phi\n",
    "\n",
    "            new_x_b.append(hidden[0])\n",
    "            new_phi.append(hidden[1])\n",
    "            new_psi.append(hidden[2])\n",
    "\n",
    "            output_by_layer.append(pred_output)\n",
    "\n",
    "            lid += 1\n",
    "\n",
    "        new_hidden = (new_x_b, new_phi, new_psi)\n",
    "\n",
    "        return (output_by_layer, new_hidden)\n",
    "\n",
    "    def _post_train_epoch(self, epoch):\n",
    "        for mod in self.children():\n",
    "            mod._post_epoch(epoch)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        param = next(self.parameters())\n",
    "        x_b = [\n",
    "            param.new_zeros((batch_size, tc), dtype=torch.float32, requires_grad=False)\n",
    "            for tc in self.total_cells\n",
    "        ]\n",
    "        phi = [\n",
    "            param.new_zeros((batch_size, tc), dtype=torch.float32, requires_grad=False)\n",
    "            for tc in self.total_cells\n",
    "        ]\n",
    "        psi = [\n",
    "            param.new_zeros((batch_size, tc), dtype=torch.float32, requires_grad=False)\n",
    "            for tc in self.total_cells\n",
    "        ]\n",
    "        return (x_b, phi, psi)\n",
    "\n",
    "\n",
    "class RSMLayer(torch.nn.Module):\n",
    "    ACT_FNS = {\"tanh\": torch.tanh, \"relu\": F.relu, \"sigmoid\": torch.sigmoid}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_in=28 * 28,\n",
    "        d_out=28 * 28,\n",
    "        d_above=None,\n",
    "        m=200,\n",
    "        n=6,\n",
    "        k=25,\n",
    "        k_winner_cells=1,\n",
    "        gamma=0.5,\n",
    "        eps=0.5,\n",
    "        activation_fn=\"tanh\",\n",
    "        decode_activation_fn=None,\n",
    "        embed_dim=0,\n",
    "        vocab_size=0,\n",
    "        decode_from_full_memory=False,\n",
    "        debug_log_names=None,\n",
    "        boost_strat=\"rsm_inhibition\",\n",
    "        x_b_norm=False,\n",
    "        boost_strength=1.0,\n",
    "        duty_cycle_period=1000,\n",
    "        mult_integration=False,\n",
    "        boost_strength_factor=1.0,\n",
    "        forget_mu=0.0,\n",
    "        weight_sparsity=None,\n",
    "        feedback_conn=False,\n",
    "        input_bias=False,\n",
    "        decode_bias=True,\n",
    "        lateral_conn=True,\n",
    "        col_output_cells=False,\n",
    "        debug=False,\n",
    "        visual_debug=False,\n",
    "        fpartition=None,\n",
    "        balance_part_winners=False,\n",
    "        trainable_decay=False,\n",
    "        trainable_decay_rec=False,\n",
    "        max_decay=1.0,\n",
    "        mem_floor=0.0,\n",
    "        additive_decay=False,\n",
    "        stoch_decay=False,\n",
    "        stoch_k_sd=0.0,\n",
    "        rec_active_dendrites=0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This class includes an attempted replication of the Recurrent Sparse Memory\n",
    "        architecture suggested by by\n",
    "        [Rawlinson et al 2019](https://arxiv.org/abs/1905.11589).\n",
    "        Parameters allow experimentation with a wide array of adjustments to this model,\n",
    "        both minor and major. Classes of models tested include:\n",
    "        * \"Adjusted\" model with k-winners and column boosting, 2 cell winners,\n",
    "            no inhibition\n",
    "        * \"Flattened\" model with 1 cell per column, 1000 cols, 25 winners\n",
    "            and multiplicative integration of FF & recurrent input\n",
    "        * \"Flat Partitioned\" model with 120 winners, and cells partitioned into three\n",
    "            functional types: ff only, recurrent only, and optionally a region that\n",
    "            integrates both.\n",
    "        :param d_in: Dimension of input\n",
    "        :param m: Number of groups/columns\n",
    "        :param n: Cells per group/column\n",
    "        :param k: # of groups/columns to win in topk() (sparsity)\n",
    "        :param k_winner_cells: # of winning cells per column\n",
    "        :param gamma: Inhibition decay rate (0-1)\n",
    "        :param eps: Integrated encoding decay rate (0-1)\n",
    "        \"\"\"\n",
    "        super(RSMLayer, self).__init__()\n",
    "        self.k = int(k)\n",
    "        self.k_winner_cells = k_winner_cells\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.d_above = d_above\n",
    "        self.forget_mu = float(forget_mu)\n",
    "\n",
    "        self.total_cells = m * n\n",
    "        self.flattened = self.total_cells == self.m\n",
    "\n",
    "        # Tweaks\n",
    "        self.activation_fn = activation_fn\n",
    "        self.decode_activation_fn = decode_activation_fn\n",
    "        self.decode_from_full_memory = decode_from_full_memory\n",
    "        self.boost_strat = boost_strat\n",
    "        self.x_b_norm = x_b_norm\n",
    "        self.boost_strength = boost_strength\n",
    "        self.boost_strength_factor = boost_strength_factor\n",
    "        self.duty_cycle_period = duty_cycle_period\n",
    "        self.mult_integration = mult_integration\n",
    "        self.fpartition = fpartition\n",
    "        if isinstance(self.fpartition, float):\n",
    "            # Handle simple single-param FF-percentage only\n",
    "            # If fpartition is list, interpreted as [ff_pct, rec_pct]\n",
    "            self.fpartition = [self.fpartition, 1.0 - self.fpartition]\n",
    "        self.balance_part_winners = balance_part_winners\n",
    "        self.weight_sparsity = weight_sparsity\n",
    "        self.feedback_conn = feedback_conn\n",
    "        self.input_bias = input_bias\n",
    "        self.decode_bias = decode_bias\n",
    "        self.lateral_conn = lateral_conn\n",
    "        self.trainable_decay = trainable_decay\n",
    "        self.trainable_decay_rec = trainable_decay_rec\n",
    "        self.max_decay = max_decay\n",
    "        self.additive_decay = additive_decay\n",
    "        self.stoch_decay = stoch_decay\n",
    "        self.col_output_cells = col_output_cells\n",
    "        self.stoch_k_sd = stoch_k_sd\n",
    "        self.rec_active_dendrites = rec_active_dendrites\n",
    "        self.mem_floor = mem_floor\n",
    "\n",
    "        self.debug = debug\n",
    "        self.visual_debug = visual_debug\n",
    "        self.debug_log_names = debug_log_names\n",
    "\n",
    "        self._build_layers_and_kwinners()\n",
    "\n",
    "        if self.additive_decay:\n",
    "            decay_init = torch.ones(self.total_cells, dtype=torch.float32).uniform_(\n",
    "                -3.0, 3.0\n",
    "            )\n",
    "        elif self.stoch_decay:\n",
    "            # Fixed random decay rates, test with trainable_decay = False\n",
    "            decay_init = torch.ones(self.total_cells, dtype=torch.float32).uniform_(\n",
    "                -3.0, 3.0\n",
    "            )\n",
    "        else:\n",
    "            decay_init = self.eps * torch.ones(self.total_cells, dtype=torch.float32)\n",
    "        self.decay = nn.Parameter(decay_init, requires_grad=self.trainable_decay)\n",
    "        self.register_parameter(\"decay\", self.decay)\n",
    "        self.learning_iterations = 0\n",
    "        self.register_buffer(\"duty_cycle\", torch.zeros(self.total_cells))\n",
    "\n",
    "        print(\n",
    "            \"Created %s with %d trainable params\" % (str(self), count_parameters(self))\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        fp = \"\"\n",
    "        if self.fpartition:\n",
    "            fp = \" partition=(%.2f,%.2f)\" % (self.fpartition[0], self.fpartition[1])\n",
    "        return \"<RSMLayer m=%d n=%d k=%d d_in=%d eps=%.2f%s />\" % (\n",
    "            self.m,\n",
    "            self.n,\n",
    "            self.k,\n",
    "            self.d_in,\n",
    "            self.eps,\n",
    "            fp,\n",
    "        )\n",
    "\n",
    "    def _debug_log(self, tensor_dict, truncate_len=400):\n",
    "        if self.debug:\n",
    "            for name, t in tensor_dict.items():\n",
    "                if not self.debug_log_names or name in self.debug_log_names:\n",
    "                    _type = type(t)\n",
    "                    if _type in [int, float, bool]:\n",
    "                        size = \"-\"\n",
    "                    else:\n",
    "                        size = t.size()\n",
    "                        _type = t.dtype\n",
    "                        if t.numel() > truncate_len:\n",
    "                            t = \"..truncated..\"\n",
    "                    print([name, t, size, _type])\n",
    "        if self.visual_debug:\n",
    "            for name, t in tensor_dict.items():\n",
    "                if not self.debug_log_names or name in self.debug_log_names:\n",
    "                    if isinstance(t, torch.Tensor):\n",
    "                        t = t.detach().squeeze()\n",
    "                        if t.dim() == 1:\n",
    "                            t = t.flatten()\n",
    "                            size = t.numel()\n",
    "                            is_cell_level = t.numel() == self.total_cells and self.n > 1\n",
    "                            if is_cell_level:\n",
    "                                plt.imshow(\n",
    "                                    t.view(self.m, self.n).t(),\n",
    "                                    origin=\"bottom\",\n",
    "                                    extent=(0, self.m - 1, 0, self.n),\n",
    "                                )\n",
    "                            else:\n",
    "                                plt.imshow(activity_square(t))\n",
    "                            tmin = t.min()\n",
    "                            tmax = t.max()\n",
    "                            tsum = t.sum()\n",
    "                            plt.title(\n",
    "                                \"%s (%s, rng: %.3f-%.3f, sum: %.3f)\"\n",
    "                                % (name, size, tmin, tmax, tsum)\n",
    "                            )\n",
    "                            plt.show()\n",
    "\n",
    "    def _build_layers_and_kwinners(self):\n",
    "        self.sparse_mods = []\n",
    "        if self.fpartition:\n",
    "            m_ff, m_int, m_rec = self._partition_sizes()\n",
    "            # Partition memory into fpartition % FF & remainder recurrent\n",
    "            self.linear_a = nn.Linear(self.d_in, m_ff, bias=self.input_bias)\n",
    "            self.linear_b = nn.Linear(\n",
    "                self.total_cells, m_rec, bias=self.input_bias\n",
    "            )  # Recurrent weights (per cell)\n",
    "            if m_int:\n",
    "                # Add two additional layers for integrating ff & rec input\n",
    "                # NOTE: Testing int layer that gets only input from prior int (no ff)\n",
    "                self.linear_a_int = nn.Linear(self.d_in, m_int, bias=self.input_bias)\n",
    "                self.linear_b_int = nn.Linear(\n",
    "                    self.total_cells, m_int, bias=self.input_bias\n",
    "                )\n",
    "        else:\n",
    "            # Standard architecture, no partition\n",
    "            self.linear_a = nn.Linear(\n",
    "                self.d_in, self.m, bias=self.input_bias\n",
    "            )  # Input weights (shared per group / proximal)\n",
    "            if self.lateral_conn:\n",
    "                d1 = d2 = self.total_cells\n",
    "                if self.col_output_cells:\n",
    "                    d1 += self.m  # One output per column\n",
    "                # Recurrent weights (per cell)\n",
    "                if self.rec_active_dendrites:\n",
    "                    sparsity = 0.3\n",
    "                    self.linear_b = ActiveDendriteLayer(\n",
    "                        d1,\n",
    "                        n_cells=d2,\n",
    "                        n_dendrites=self.rec_active_dendrites,\n",
    "                        sparsity=sparsity,\n",
    "                    )\n",
    "                    if sparsity:\n",
    "                        self.sparse_mods.append(self.linear_b.linear_dend)\n",
    "                else:\n",
    "                    self.linear_b = nn.Linear(d1, d2, bias=self.input_bias)\n",
    "\n",
    "            if self.feedback_conn:\n",
    "                # Linear layers for both recurrent input from above and below\n",
    "                self.linear_b_above = nn.Linear(\n",
    "                    self.d_above, self.total_cells, bias=self.input_bias\n",
    "                )\n",
    "\n",
    "        pct_on = self.k / self.m\n",
    "        if self.fpartition and self.balance_part_winners:\n",
    "            # Create a kwinners module for each partition each with specified\n",
    "            # size but same pct on (balanced).\n",
    "            self.kwinners_ff = self.kwinners_rec = self.kwinners_int = None\n",
    "            if m_ff:\n",
    "                self.kwinners_ff = self._build_kwinner_mod(m_ff, pct_on)\n",
    "            if m_int:\n",
    "                self.kwinners_int = self._build_kwinner_mod(m_int, pct_on)\n",
    "            if m_rec:\n",
    "                self.kwinners_rec = self._build_kwinner_mod(m_rec, pct_on)\n",
    "        else:\n",
    "            # We need only a single kwinners to run on full memory\n",
    "            self.kwinners_col = self._build_kwinner_mod(self.m, pct_on)\n",
    "        if self.weight_sparsity is not None:\n",
    "            self.linear_a = SparseWeights(self.linear_a, self.weight_sparsity)\n",
    "            self.linear_b = SparseWeights(self.linear_b, self.weight_sparsity)\n",
    "            self.sparse_mods.extend([self.linear_a, self.linear_b])\n",
    "\n",
    "        # Decode linear\n",
    "        decode_d_in = self.total_cells if self.decode_from_full_memory else self.m\n",
    "        self.linear_d = nn.Linear(decode_d_in, self.d_out, bias=self.decode_bias)\n",
    "\n",
    "        if self.trainable_decay_rec:\n",
    "            self.linear_decay_rec = nn.Linear(\n",
    "                self.total_cells, self.total_cells, bias=True\n",
    "            )\n",
    "\n",
    "        self._init_linear_weights()\n",
    "\n",
    "    def _init_linear_weights(self):\n",
    "        for mod in self.modules():\n",
    "            if isinstance(mod, nn.Linear):\n",
    "                sd = 0.03\n",
    "                mod.weight.data.normal_(0.0, sd)\n",
    "                if mod.bias is not None:\n",
    "                    mod.bias.data.normal_(0.0, sd)\n",
    "\n",
    "    def _zero_sparse_weights(self):\n",
    "        for mod in self.sparse_mods:\n",
    "            if isinstance(mod, SparseWeights):\n",
    "                mod.rezero_weights()\n",
    "\n",
    "    def _partition_sizes(self):\n",
    "        pct_ff, pct_rec = self.fpartition\n",
    "        m_ff = int(round(pct_ff * self.m))\n",
    "        m_rec = int(round(pct_rec * self.m))\n",
    "        m_int = self.m - m_ff - m_rec\n",
    "        return (m_ff, m_int, m_rec)\n",
    "\n",
    "    def _build_kwinner_mod(self, m, pct_on):\n",
    "        return KWinners(\n",
    "            m,\n",
    "            pct_on,\n",
    "            boost_strength=self.boost_strength,\n",
    "            duty_cycle_period=self.duty_cycle_period,\n",
    "            k_inference_factor=1.0,\n",
    "            stoch_sd=self.stoch_k_sd,\n",
    "            boost_strength_factor=self.boost_strength_factor,\n",
    "        )\n",
    "\n",
    "    def _post_epoch(self, epoch):\n",
    "        # Update boost strength of any KWinners modules\n",
    "        for mod in self.modules():\n",
    "            if hasattr(mod, \"update_boost_strength\"):\n",
    "                mod.update_boost_strength()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        \"\"\"Utility function to call retain_grad and Pytorch's register_hook\n",
    "        in a single line\n",
    "        \"\"\"\n",
    "        for label, t in [\n",
    "            # ('y', self.y),\n",
    "            # ('sigma', self.sigma),\n",
    "            (\"linear_b grad\", self.linear_b.weight)\n",
    "        ]:\n",
    "            t.retain_grad()\n",
    "            t.register_hook(get_grad_printer(label))\n",
    "\n",
    "    def _decay_memory(self, psi_last, x_b):\n",
    "        if self.trainable_decay_rec:\n",
    "            decay_param = self.max_decay * torch.sigmoid(\n",
    "                self.linear_decay_rec(psi_last)\n",
    "            )\n",
    "        elif self.trainable_decay:\n",
    "            decay_param = self.max_decay * torch.sigmoid(self.decay)\n",
    "        else:\n",
    "            decay_param = self.eps\n",
    "        \n",
    "        updated = decay_param * psi_last\n",
    "        if self.mem_floor:\n",
    "            updated[updated <= self.mem_floor] = 0.0\n",
    "        memory = torch.max(updated, x_b)\n",
    "        return memory\n",
    "\n",
    "    def _do_forgetting(self, phi, psi):\n",
    "        bsz = phi.size(0)\n",
    "        if self.training and self.forget_mu > 0:\n",
    "            keep_idxs = torch.rand(bsz) > self.forget_mu\n",
    "            mask = torch.zeros_like(phi)\n",
    "            mask[keep_idxs, :] = 1\n",
    "            phi = phi * mask\n",
    "            psi = psi * mask\n",
    "        return (phi, psi)\n",
    "\n",
    "    def _group_max(self, activity):\n",
    "        \"\"\"\n",
    "        :param activity: activity vector (bsz x total_cells)\n",
    "        Returns max cell activity in each group\n",
    "        \"\"\"\n",
    "        return activity.view(-1, self.m, self.n).max(dim=2).values\n",
    "\n",
    "    def _fc_weighted_ave(self, x_a, x_b, x_b_above=None):\n",
    "        \"\"\"\n",
    "        Compute sigma (weighted sum for each cell j in group i (mxn))\n",
    "        \"\"\"\n",
    "        if self.fpartition:\n",
    "            m_ff, m_int, m_rec = self._partition_sizes()\n",
    "            sigma = torch.zeros_like(x_b)\n",
    "            # Integrate partitioned memory.\n",
    "            # Pack as 1xm: [ ... m_ff ... ][ ... m_int ... ][ ... m_rec ... ]\n",
    "            # If m_int non-zero, these cells receive sum of FF & recurrent input\n",
    "            z_a = self.linear_a(x_a)  # bsz x (m_ff)\n",
    "            z_log = {\"z_a\": z_a}\n",
    "            if m_int:\n",
    "                z_b = self.linear_b(x_b)  # bsz x m_rec\n",
    "                z_int_ff = self.linear_a_int(x_a)\n",
    "                # NOTE: Testing from only int/rec portion of mem (no ff)\n",
    "                z_int_rec = self.linear_b_int(x_b)\n",
    "                z_int = (\n",
    "                    z_int_ff * z_int_rec\n",
    "                    if self.mult_integration\n",
    "                    else z_int_ff + z_int_rec\n",
    "                )\n",
    "                sigma = torch.cat((z_a, z_int, z_b), 1)  # bsz x m\n",
    "            else:\n",
    "                z_b = self.linear_b(x_b)  # bsz x m_rec\n",
    "                z_log[\"z_b\"] = z_b\n",
    "                sigma = torch.cat((z_a, z_b), 1)  # bsz x m\n",
    "        else:\n",
    "            # Col activation from inputs repeated for each cell\n",
    "            z_a = self.linear_a(x_a).repeat_interleave(self.n, 1)\n",
    "\n",
    "            sigma = z_a\n",
    "            z_log = {\"z_a\": z_a}\n",
    "\n",
    "            # Cell activation from recurrent (lateral) input\n",
    "            if self.lateral_conn:\n",
    "                z_b_in = x_b\n",
    "                if self.col_output_cells:\n",
    "                    z_b_in = torch.cat((z_b_in, self._group_max(x_b)), dim=1)\n",
    "                z_b = self.linear_b(z_b_in)\n",
    "                sigma = sigma * z_b if self.mult_integration else sigma + z_b\n",
    "                z_log[\"z_b\"] = z_b\n",
    "            # Activation from recurrent (feedback) input\n",
    "            if self.feedback_conn:\n",
    "                if x_b_above is not None:\n",
    "                    # Cell activation from recurrent input from layer above (apical)\n",
    "                    z_b_above = self.linear_b_above(x_b_above)\n",
    "                    z_log[\"z_b_above\"] = z_b_above\n",
    "                    if self.mult_integration:\n",
    "                        sigma = sigma * z_b_above\n",
    "                    else:\n",
    "                        sigma = sigma + z_b_above\n",
    "        self._debug_log(z_log)\n",
    "\n",
    "        return sigma  # total_cells\n",
    "\n",
    "    def _update_duty_cycle(self, winners):\n",
    "        \"\"\"\n",
    "        For tracking layer entropy (across both inhibition/boosting approaches)\n",
    "        \"\"\"\n",
    "        batch_size = winners.shape[0]\n",
    "        self.learning_iterations += batch_size\n",
    "        period = min(1000, self.learning_iterations)\n",
    "        self.duty_cycle.mul_(period - batch_size)\n",
    "\n",
    "        self.duty_cycle.add_(winners.gt(0).sum(dim=0, dtype=torch.float))\n",
    "        self.duty_cycle.div_(period)\n",
    "\n",
    "    def _k_winners(self, sigma, pi):\n",
    "        bsz = pi.size(0)\n",
    "\n",
    "        # Group-wise max pooling\n",
    "        if not self.flattened:\n",
    "            lambda_ = self._group_max(pi)\n",
    "        else:\n",
    "            lambda_ = pi\n",
    "\n",
    "        # Cell-level mask: Make a bsz x total_cells binary mask of top 1 cell / column\n",
    "        if self.n == self.k_winner_cells:\n",
    "            # Usually just in flattened case, no need to choose winners\n",
    "            m_pi = torch.ones(bsz, self.total_cells, device=sigma.device)\n",
    "        else:\n",
    "            mask = topk_mask(pi.view(bsz * self.m, self.n), self.k_winner_cells)\n",
    "            m_pi = mask.view(bsz, self.total_cells).detach()\n",
    "\n",
    "        if self.boost_strat == \"rsm_inhibition\":\n",
    "            # Standard RSM-style inhibition via phi matrix\n",
    "\n",
    "            self._debug_log({\"lambda_\": lambda_})\n",
    "\n",
    "            # Column-level mask: Make a bsz x total_cells binary mask of top k columns\n",
    "            mask = topk_mask(lambda_, self.k)\n",
    "            m_lambda = (\n",
    "                mask.view(bsz, self.m, 1)\n",
    "                .repeat(1, 1, self.n)\n",
    "                .view(bsz, self.total_cells)\n",
    "                .detach()\n",
    "            )\n",
    "            col_winners = m_lambda\n",
    "\n",
    "            self._debug_log({\"m_pi\": m_pi, \"m_lambda\": m_lambda})\n",
    "\n",
    "            y_pre_act = m_pi * m_lambda * sigma\n",
    "\n",
    "        elif self.boost_strat == \"col_boosting\":\n",
    "            # HTM style boosted k-winner\n",
    "            if self.balance_part_winners and self.fpartition:\n",
    "                m_ff, m_int, m_rec = self._partition_sizes()\n",
    "                winners = []\n",
    "                if self.kwinners_ff is not None:\n",
    "                    winners_ff = self.kwinners_ff(lambda_[:, :m_ff])\n",
    "                    winners.append(winners_ff)\n",
    "                if self.kwinners_int is not None:\n",
    "                    winners_int = self.kwinners_int(lambda_[:, m_ff : m_ff + m_int])\n",
    "                    winners.append(winners_int)\n",
    "                if self.kwinners_rec is not None:\n",
    "                    winners_rec = self.kwinners_rec(lambda_[:, -m_rec:])\n",
    "                    winners.append(winners_rec)\n",
    "                m_lambda = (torch.cat(winners, 1).abs() > 0).float()\n",
    "            else:\n",
    "                \n",
    "                winning_cols = (\n",
    "                    self.kwinners_col(lambda_).view(bsz, self.m, 1).abs() > 0\n",
    "                ).float()\n",
    "              \n",
    "                m_lambda = winning_cols.repeat(1, 1, self.n).view(bsz, self.total_cells)\n",
    "\n",
    "                col_winners = winning_cols\n",
    "\n",
    "            self._debug_log({\"m_lambda\": m_lambda})\n",
    "\n",
    "            y_pre_act = m_pi * m_lambda * sigma\n",
    "\n",
    "        self._update_duty_cycle(col_winners.squeeze())\n",
    "\n",
    "        del m_pi\n",
    "        del m_lambda\n",
    "\n",
    "        return y_pre_act\n",
    "\n",
    "    def _inhibited_winners(self, sigma, phi):\n",
    "        \"\"\"\n",
    "        Compute y_lambda\n",
    "        \"\"\"\n",
    "        # Apply inhibition to non-neg shifted sigma\n",
    "        inh = (1 - phi) if self.boost_strat == \"rsm_inhibition\" else 1\n",
    "        pi = inh * (sigma - sigma.min() + 1)\n",
    "        self._debug_log({\"pi\": pi})\n",
    "\n",
    "        pi = pi.detach()  # Prevent gradients from flowing through inhibition/masking\n",
    "\n",
    "        y_pre_act = self._k_winners(sigma, pi)\n",
    "\n",
    "        activation = RSMLayer.ACT_FNS[self.activation_fn]\n",
    "        y = activation(y_pre_act)  # 1 x total_cells\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _update_memory_and_inhibition(self, y, phi, psi, x_b=None):\n",
    "        \"\"\"\n",
    "        Decay memory and inhibition tensors\n",
    "        \"\"\"\n",
    "\n",
    "        # Set psi to x_b, which includes decayed prior state (see RSMNet.forward)\n",
    "        psi = x_b\n",
    "\n",
    "        # Update phi for next step (decay inhibition cells)\n",
    "        phi = torch.max(phi * self.gamma, y)\n",
    "\n",
    "        return (phi, psi)\n",
    "\n",
    "    def _decode_prediction(self, y):\n",
    "        if self.decode_from_full_memory:\n",
    "            decode_input = y\n",
    "        else:\n",
    "            decode_input = self._group_max(y)\n",
    "        output = self.linear_d(decode_input)\n",
    "        if self.decode_activation_fn:\n",
    "            activation = RSMLayer.ACT_FNS[self.decode_activation_fn]\n",
    "            output = activation(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_a_batch, hidden):\n",
    "        \"\"\"\n",
    "        :param x_a_batch: Input batch of batch_size items from\n",
    "        generating process (batch_size, d_in)\n",
    "        :param hidden:\n",
    "            x_b: Memory at same layer at t-1 (possibly with decayed/hysteresis memory\n",
    "                from prior time steps)\n",
    "            x_b_above: memory state at layer above at t-1\n",
    "            phi: inhibition state (used only for boost_strat=='rsm_inhibition')\n",
    "            psi: memory state at t-1, inclusive of hysteresis\n",
    "        Note that RSMLayer takes a 4-tuple that includes the feedback state\n",
    "        from the layer above, x_c, while the RSMNet takes only 3-tuple for\n",
    "        hidden state.\n",
    "        \"\"\"\n",
    "        x_b, x_b_above, phi, psi = hidden\n",
    "        x_b_in = x_b.clone()\n",
    "\n",
    "        phi, psi = self._do_forgetting(phi, psi)\n",
    "\n",
    "        self._debug_log({\"x_b\": x_b, \"x_a_batch\": x_a_batch})\n",
    "\n",
    "        sigma = self._fc_weighted_ave(x_a_batch, x_b, x_b_above=x_b_above)\n",
    "        self._debug_log({\"sigma\": sigma})\n",
    "\n",
    "        y = self._inhibited_winners(sigma, phi)\n",
    "\n",
    "        phi, psi = self._update_memory_and_inhibition(y, phi, psi, x_b=x_b_in)\n",
    "        self._debug_log({\"phi\": phi, \"psi\": psi})\n",
    "\n",
    "        output = self._decode_prediction(y)\n",
    "\n",
    "        self._debug_log({\"y\": y, \"output\": output})\n",
    "\n",
    "        # Update recurrent input / output x_b\n",
    "        if self.x_b_norm:\n",
    "            # Normalizing scalar (force sum(x_b) == 1)\n",
    "            alpha_y = (y.sum(dim=1) + 1e-9).unsqueeze(dim=1)\n",
    "            x_b = y / alpha_y\n",
    "        else:\n",
    "            x_b = y\n",
    "\n",
    "        hidden = (x_b, phi, psi)\n",
    "        return (output, hidden)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size, d_in = 50, 64\n",
    "\n",
    "    x = torch.randn(batch_size, d_in)\n",
    "    y = torch.randn(batch_size, d_in)\n",
    "\n",
    "    model = RSMLayer(d_in)\n",
    "\n",
    "    criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "    for t in range(500):\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(t, loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.logger import CSVLogger, JsonLogger\n",
    "\n",
    "\n",
    "from parse_config import parse_config\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from functools import partial, reduce\n",
    "\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from duty_cycle_metrics import binary_entropy\n",
    "from ptb import lang_util\n",
    "from rsm import RSMNet, RSMPredictor\n",
    "from rsm_samplers import (\n",
    "    PTBSequenceSampler,\n",
    "    pred_sequence_collate,\n",
    "    ptb_pred_sequence_collate,\n",
    ")\n",
    "from util import (\n",
    "    fig2img,\n",
    "    plot_activity,\n",
    "    plot_activity_grid,\n",
    "    plot_confusion_matrix,\n",
    "    plot_representation_similarity,\n",
    "    plot_tensors,\n",
    "    print_aligned_sentences,\n",
    "    print_epoch_values,\n",
    ")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "class RSMExperiment(object):\n",
    "    \"\"\"\n",
    "    Generic class for creating tiny RSM models. This can be used with Ray\n",
    "    tune or PyExperimentSuite, to run a single trial or repetition of a\n",
    "    network.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.data_dir = config.get(\"data_dir\", \"/home/user/nta/datasets\") #hardcode please change this one \n",
    "        self.path = config.get(\"path\", \"/home/user/nta/results\") #hardcode please change this one\n",
    "        self.model_filename = config.get(\"model_filename\", \"model.pt\")\n",
    "        self.pred_model_filename = config.get(\"pred_model_filename\", \"pred_model.pt\")\n",
    "        self.graph_filename = config.get(\"graph_filename\", \"rsm.onnx\")\n",
    "        self.save_onnx_graph_at_checkpoint = config.get(\n",
    "            \"save_onnx_graph_at_checkpoint\", False\n",
    "        )\n",
    "        self.exp_name = config.get(\"name\", \"exp\")\n",
    "        self.batch_log_interval = config.get(\"batch_log_interval\", 0)\n",
    "        self.eval_interval = config.get(\"eval_interval\", 1)\n",
    "        self.eval_interval_schedule = config.get(\"eval_interval_schedule\", None)\n",
    "        self.model_kind = config.get(\"model_kind\", \"rsm\")\n",
    "        self.debug = config.get(\"debug\", False)\n",
    "        self.visual_debug = config.get(\"visual_debug\", False)\n",
    "\n",
    "        # Instrumentation\n",
    "        self.instrumentation = config.get(\"instrumentation\", False)\n",
    "        self.plot_gradients = config.get(\"plot_gradients\", False)\n",
    "        self.instr_charts = config.get(\"instr_charts\", [])\n",
    "\n",
    "        self.iterations = config.get(\"iterations\", 1)\n",
    "        self.dataset_kind = config.get(\"dataset\", \"ptb\")\n",
    "\n",
    "        # Training / testing parameters\n",
    "        self.batch_size = config.get(\"batch_size\", 100)\n",
    "        self.eval_batch_size = config.get(\"eval_batch_size\", 11)\n",
    "        self.batches_in_epoch = config.get(\"batches_in_epoch\", 100) #number of game per epoch\n",
    "        self.batches_in_first_epoch = config.get(\n",
    "            \"batches_in_first_epoch\", self.batches_in_epoch\n",
    "        )\n",
    "        self.eval_batches_in_epoch = config.get(\n",
    "            \"eval_batches_in_epoch\", self.batches_in_epoch\n",
    "        )\n",
    "        self.pause_after_upticks = config.get(\"pause_after_upticks\", 0)\n",
    "        self.pause_after_epochs = config.get(\"pause_after_epochs\", 0)\n",
    "        self.pause_eval_interval = config.get(\"pause_eval_interval\", 10)\n",
    "        self.pause_min_epoch = config.get(\"pause_min_epoch\", 0)\n",
    "\n",
    "        # Data parameters\n",
    "        self.input_size = config.get(\"input_size\", (1, 100)) #(1, 28, 28)\n",
    "        self.sequences = config.get(\"sequences\", [[0, 1, 2, 3]])\n",
    "        self.static_digit = config.get(\"static_digit\", False)\n",
    "        self.randomize_sequence_cursors = config.get(\"randomize_sequence_cursors\", True)\n",
    "#        self.use_mnist_pct = config.get(\"use_mnist_pct\", 1.0)\n",
    "\n",
    "        self.learning_rate = config.get(\"learning_rate\", 0.0005)\n",
    "        self.pred_learning_rate = config.get(\"pred_learning_rate\", self.learning_rate)\n",
    "        self.momentum = config.get(\"momentum\", 0.9)\n",
    "        self.optimizer_type = config.get(\"optimizer\", \"adam\")\n",
    "        self.pred_optimizer_type = config.get(\"pred_optimizer\", self.optimizer_type)\n",
    "\n",
    "        # Model\n",
    "        self.heads = config.get(\"heads\", 1)\n",
    "        self.m_groups = config.get(\"m_groups\", 60)\n",
    "        self.n_cells_per_group = config.get(\"n_cells_per_group\", 1)\n",
    "        self.k_winners = config.get(\"k_winners\", 7)\n",
    "        self.k_winners_pct = config.get(\"k_winners_pct\", None)\n",
    "        if self.k_winners_pct is not None:\n",
    "            # Optionally define k-winners proportionally\n",
    "            self.k_winners = int(self.m_groups * self.k_winners_pct)\n",
    "        self.gamma = config.get(\"gamma\", 0.5)\n",
    "        self.eps = config.get(\"eps\", 0.5)\n",
    "        self.k_winner_cells = config.get(\"k_winner_cells\", 1)\n",
    "        self.flattened = self.n_cells_per_group == 1\n",
    "        self.forget_mu = config.get(\"forget_mu\", 0.0)\n",
    "\n",
    "        # Tweaks\n",
    "        self.activation_fn = config.get(\"activation_fn\", \"tanh\")\n",
    "        self.decode_activation_fn = config.get(\"decode_activation_fn\", None)\n",
    "        self.pred_l2_reg = config.get(\"pred_l2_reg\", 0)\n",
    "        self.l2_reg = config.get(\"l2_reg\", 0)\n",
    "        self.dec_l2_reg = config.get(\"dec_l2_reg\", 0)\n",
    "        self.decode_from_full_memory = config.get(\"decode_from_full_memory\", False)\n",
    "        self.boost_strat = config.get(\"boost_strat\", \"col_boosting\")\n",
    "        self.x_b_norm = config.get(\"x_b_norm\", False)\n",
    "        self.mask_shifted_pi = config.get(\"mask_shifted_pi\", False)\n",
    "        self.boost_strength = config.get(\"boost_strength\", 1.0)\n",
    "        self.boost_strength_factor = config.get(\"boost_strength_factor\", 1.0)\n",
    "        self.duty_cycle_period = config.get(\"duty_cycle_period\", 1000)\n",
    "        self.mult_integration = config.get(\"mult_integration\", False)\n",
    "        self.noise_buffer = config.get(\"noise_buffer\", False)\n",
    "        self.col_output_cells = config.get(\"col_output_cells\", False)\n",
    "        self.fpartition = config.get(\"fpartition\", None)\n",
    "        self.balance_part_winners = config.get(\"balance_part_winners\", False)\n",
    "        self.weight_sparsity = config.get(\"weight_sparsity\", None)\n",
    "        self.embedding_kind = config.get(\"embedding_kind\", \"ptb_fasttext_e5\")\n",
    "        self.feedback_conn = config.get(\"feedback_conn\", False)\n",
    "        self.input_bias = config.get(\"input_bias\", False)\n",
    "        self.decode_bias = config.get(\"decode_bias\", True)\n",
    "        self.loss_layers = config.get(\"loss_layers\", \"first\")\n",
    "        self.top_lateral_conn = config.get(\"top_lateral_conn\", True)\n",
    "        self.lateral_conn = config.get(\"lateral_conn\", True)\n",
    "        self.trainable_decay = config.get(\"trainable_decay\", True)\n",
    "        self.trainable_decay_rec = config.get(\"trainable_decay_rec\", False)\n",
    "        self.max_decay = config.get(\"max_decay\", 1.0)\n",
    "        self.additive_decay = config.get(\"additive_decay\", False)\n",
    "        self.stoch_decay = config.get(\"stoch_decay\", False)\n",
    "        self.stoch_k_sd = config.get(\"stoch_k_sd\", False)\n",
    "        self.rec_active_dendrites = config.get(\"rec_active_dendrites\", 0)\n",
    "        self.mem_floor = config.get(\"mem_floor\", 0.0)\n",
    "\n",
    "        # Prediction smoothing\n",
    "        self.word_cache_decay = config.get(\"word_cache_decay\", 0.0)\n",
    "        self.word_cache_pct = config.get(\"word_cache_pct\", 0.0)\n",
    "        self.unif_smoothing = config.get(\"unif_smoothing\", 0.0)\n",
    "        self.kn5_pct = config.get(\"kn5_pct\", 0.0)\n",
    "\n",
    "        # Predictor network\n",
    "        self.predictor_hidden_size = config.get(\"predictor_hidden_size\", 200)\n",
    "        self.predictor_output_size = config.get(\"predictor_output_size\", 10000)\n",
    "\n",
    "        self.n_layers = config.get(\"n_layers\", 1)\n",
    "\n",
    "        # Embeddings for language modeling\n",
    "        self.embed_dim = config.get(\"embed_dim\", 100)\n",
    "        self.vocab_size = config.get(\"vocab_size\", 0)\n",
    "\n",
    "        self.loss_function = config.get(\"loss_function\", \"MSELoss\")\n",
    "        self.lr_step_schedule = config.get(\"lr_step_schedule\", None)\n",
    "        self.learning_rate_gamma = config.get(\"learning_rate_gamma\", 0.0)\n",
    "        self.learning_rate_min = config.get(\"learning_rate_min\", 0.0)\n",
    "\n",
    "        # Training state\n",
    "        self.best_val_loss = None\n",
    "        self.do_anneal_learning = False\n",
    "        self.model_learning_paused = False\n",
    "        self.n_upticks = 0\n",
    "\n",
    "        self.train_hidden_buffer = []\n",
    "\n",
    "        # Additional state for vis, etc\n",
    "        self.activity_by_inputs = {}  # 'digit-digit' -> list of distribution arrays\n",
    "\n",
    "    def _build_dataloader(self):\n",
    "        self.val_loader = self.corpus = None\n",
    "        \n",
    "        # Download \"Penn Treebank\" dataset\n",
    "        from torchnlp.datasets import penn_treebank_dataset\n",
    "\n",
    "        print(\"Maybe download PTB...\")\n",
    "        penn_treebank_dataset(self.data_dir + \"/PTB\", train=True, test=True)\n",
    "        corpus = lang_util.Corpus(self.data_dir + \"/PTB\")\n",
    "        train_sampler = PTBSequenceSampler(\n",
    "            corpus.train,\n",
    "            batch_size=self.batch_size,\n",
    "            max_batches=self.batches_in_epoch,\n",
    "        )\n",
    "\n",
    "        import fasttext\n",
    "\n",
    "        # Generated via notebooks/ptb_embeddings.ipynb\n",
    "        embedding = {}\n",
    "        ft_model = fasttext.load_model(\n",
    "            self.data_dir + \"/embeddings/%s.bin\" % self.embedding_kind\n",
    "        )\n",
    "        for word_id, word in enumerate(corpus.dictionary.idx2word):\n",
    "            embedding[word_id] = torch.tensor(ft_model[word])\n",
    "\n",
    "        if self.embedding_kind:\n",
    "            print(\n",
    "                \"Loaded embedding dict (%s) with %d entries\"\n",
    "                % (self.embedding_kind, len(embedding))\n",
    "            )\n",
    "\n",
    "        collate_fn = partial(ptb_pred_sequence_collate, vector_dict=embedding)\n",
    "        self.train_loader = DataLoader(\n",
    "            corpus.train, batch_sampler=train_sampler, collate_fn=collate_fn\n",
    "        )\n",
    "        val_sampler = PTBSequenceSampler(\n",
    "            corpus.test,\n",
    "            batch_size=self.eval_batch_size,\n",
    "            max_batches=self.eval_batches_in_epoch,\n",
    "            uniform_offsets=True,\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            corpus.test, \n",
    "            batch_sampler=val_sampler, \n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        self.corpus = corpus\n",
    "        print(\"Built dataloaders...\")\n",
    "\n",
    "    def _get_loss_function(self):\n",
    "        self.loss = getattr(torch.nn, self.loss_function)(reduction=\"mean\")\n",
    "        self.predictor_loss = None\n",
    "        if self.predictor:\n",
    "            # https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "            self.predictor_loss = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_one_optimizer(self, otype, params, lr, l2_reg=0.0):\n",
    "        if otype == \"adam\":\n",
    "            optimizer = torch.optim.Adam(params, lr=lr, weight_decay=l2_reg)\n",
    "        elif otype == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params, lr=lr, momentum=self.momentum, weight_decay=l2_reg\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        self.pred_optimizer = None\n",
    "        self.optimizer = self._get_one_optimizer(\n",
    "            self.optimizer_type, self.model.parameters(), self.learning_rate\n",
    "        )\n",
    "        if self.predictor:\n",
    "            self.pred_optimizer = self._get_one_optimizer(\n",
    "                self.pred_optimizer_type,\n",
    "                self.predictor.parameters(),\n",
    "                self.pred_learning_rate,\n",
    "                l2_reg=self.pred_l2_reg,\n",
    "            )\n",
    "\n",
    "    def model_setup(self, config, restore_path=None):\n",
    "        seed = config.get(\"seed\", random.randint(0, 10000))\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"setup: Using cuda\")\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            torch.cuda.manual_seed(seed)\n",
    "        else:\n",
    "            print(\"setup: Using cpu\")\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        self._build_dataloader()\n",
    "\n",
    "        if restore_path:\n",
    "            # Restore to self.model and self.predictor\n",
    "            self.model_restore(restore_path)\n",
    "        else:\n",
    "            # Build model and optimizer\n",
    "            self.d_in = reduce(lambda x, y: x * y, self.input_size)\n",
    "            #print('inpust size',self.input_size)\n",
    "            self.d_out = config.get(\"output_size\", self.d_in)\n",
    "            self.predictor = None\n",
    "            predictor_d_in = self.m_groups\n",
    "            self.model = RSMNet(\n",
    "                n_layers=self.n_layers,\n",
    "                d_in=self.d_in,\n",
    "                d_out=self.d_out,\n",
    "                m=self.m_groups,\n",
    "                n=self.n_cells_per_group,\n",
    "                k=self.k_winners,\n",
    "                k_winner_cells=self.k_winner_cells,\n",
    "                gamma=self.gamma,\n",
    "                eps=self.eps,\n",
    "                forget_mu=self.forget_mu,\n",
    "                activation_fn=self.activation_fn,\n",
    "                decode_activation_fn=self.decode_activation_fn,\n",
    "                decode_from_full_memory=self.decode_from_full_memory,\n",
    "                col_output_cells=self.col_output_cells,\n",
    "                x_b_norm=self.x_b_norm,\n",
    "                mask_shifted_pi=self.mask_shifted_pi,\n",
    "                boost_strat=self.boost_strat,\n",
    "                boost_strength=self.boost_strength,\n",
    "                boost_strength_factor=self.boost_strength_factor,\n",
    "                duty_cycle_period=self.duty_cycle_period,\n",
    "                weight_sparsity=self.weight_sparsity,\n",
    "                mult_integration=self.mult_integration,\n",
    "                fpartition=self.fpartition,\n",
    "                balance_part_winners=self.balance_part_winners,\n",
    "                feedback_conn=self.feedback_conn,\n",
    "                lateral_conn=self.lateral_conn,\n",
    "                top_lateral_conn=self.top_lateral_conn,\n",
    "                input_bias=self.input_bias,\n",
    "                decode_bias=self.decode_bias,\n",
    "                trainable_decay=self.trainable_decay,\n",
    "                trainable_decay_rec=self.trainable_decay_rec,\n",
    "                max_decay=self.max_decay,\n",
    "                additive_decay=self.additive_decay,\n",
    "                stoch_decay=self.stoch_decay,\n",
    "                embed_dim=self.embed_dim,\n",
    "                vocab_size=self.vocab_size,\n",
    "                stoch_k_sd=self.stoch_k_sd,\n",
    "                rec_active_dendrites=self.rec_active_dendrites,\n",
    "                mem_floor=self.mem_floor,\n",
    "                debug=self.debug,\n",
    "                visual_debug=self.visual_debug,\n",
    "            )\n",
    "            if self.n_layers > 1:\n",
    "                predictor_d_in = sum([l.total_cells for l in self.model.children()])\n",
    "            else:\n",
    "                predictor_d_in = self.m_groups * self.n_cells_per_group\n",
    "\n",
    "            if self.predictor_hidden_size:\n",
    "                self.predictor = RSMPredictor(\n",
    "                    d_in=predictor_d_in,\n",
    "                    d_out=self.predictor_output_size,\n",
    "                    hidden_size=self.predictor_hidden_size,\n",
    "                )\n",
    "\n",
    "        # Move to device\n",
    "        self.model.to(self.device)\n",
    "        if self.predictor:\n",
    "            self.predictor.to(self.device)\n",
    "\n",
    "        self._get_loss_function()\n",
    "        self._get_optimizer()\n",
    "\n",
    "        if self.word_cache_decay:\n",
    "            self.word_cache = torch.zeros(\n",
    "                (self.eval_batch_size, self.vocab_size),\n",
    "                device=self.device,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "\n",
    "        if self.kn5_pct:\n",
    "            # This KN5 model likely needs to be generated / downloaded\n",
    "            self.kn5_distr = torch.load(\n",
    "                self.data_dir + \"/PTB/KN5/kn5_distr_remapped.pt\",\n",
    "                map_location=self.device,\n",
    "            )\n",
    "\n",
    "    def _repackage_hidden(self, h):\n",
    "        \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "        if isinstance(h, torch.Tensor):\n",
    "            return h.detach()\n",
    "        else:\n",
    "            return tuple(self._repackage_hidden(v) for v in h)\n",
    "\n",
    "    def _adjust_learning_rate(self, epoch):\n",
    "        if self.do_anneal_learning and self.learning_rate > self.learning_rate_min:\n",
    "            self.learning_rate *= self.learning_rate_gamma\n",
    "            self.do_anneal_learning = False\n",
    "            print(\n",
    "                \"Reducing learning rate by gamma %.2f to: %.5f\"\n",
    "                % (self.learning_rate_gamma, self.learning_rate)\n",
    "            )\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = self.learning_rate\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        return self.model.init_hidden(batch_size)\n",
    "\n",
    "    def _cache_inputs(self, input_labels, clear=False):\n",
    "        \"\"\"\n",
    "        Word cache for smoothing, currently only used for eval (on test)\n",
    "        \"\"\"\n",
    "        if self.word_cache_decay:\n",
    "            if clear:\n",
    "                # Clear cache\n",
    "                self.word_cache = self.word_cache * 0.0\n",
    "\n",
    "            self.word_cache.scatter_(1, input_labels.unsqueeze(1), 1.0)\n",
    "            # Decay\n",
    "            self.word_cache = self.word_cache * self.word_cache_decay\n",
    "\n",
    "    def _get_prediction_and_loss_inputs(self, hidden):\n",
    "        # hidden is (x_b, phi, psi)\n",
    "        x_b = hidden[0]\n",
    "        #print('self.predictor',self.predictor)\n",
    "        #print('torch.cat(x_b, dim=1).view(-1, self.predictor.d_in).detach() = ',torch.cat(x_b, dim=1).view(-1, self.predictor.d_in).detach())\n",
    "        #print('x_b at 437',x_b[0].shape)\n",
    "        if self.predictor:\n",
    "            # Predict from concat of all layer hidden states\n",
    "            predictor_input = (\n",
    "                torch.cat(x_b, dim=1).view(-1,self.predictor.d_in).detach()\n",
    "            ) #remember to change 31 to batchsize later on\n",
    "            \n",
    "        #print('predictor_input at 444',predictor_input.shape)\n",
    "        return x_b, predictor_input\n",
    "\n",
    "    def _backward_and_optimize(self, loss):\n",
    "        if self.debug:\n",
    "            self.model._register_hooks()\n",
    "        loss.backward()\n",
    "        if self.model_kind == \"lstm\":\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "            for p in self.model.parameters():\n",
    "                p.data.add_(-self.learning_rate, p.grad.data)\n",
    "        else:\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def _interpolated_loss(\n",
    "        self, predictor_dist, pred_targets, loader=None, train=False\n",
    "    ):\n",
    "        predictor_dist_size = list(predictor_dist.size())\n",
    "        num_classes = predictor_dist_size[1]\n",
    "        \n",
    "        #print('pred_targets ',pred_targets)\n",
    "        #print('num_classes ',num_classes)\n",
    "        \n",
    "        labels_one_hot = torch.nn.functional.one_hot(\n",
    "            pred_targets, num_classes=num_classes\n",
    "        )\n",
    "        labels_one_hot = labels_one_hot.to(self.device).float()\n",
    "\n",
    "        predictions = torch.zeros_like(predictor_dist)\n",
    "        predictor_mass_pct = 1.0\n",
    "        if not train:\n",
    "            if (\n",
    "                self.word_cache_decay\n",
    "            ):  # and predictions.size(0) == self.word_cache.size(0):\n",
    "                # Word cache enabled\n",
    "                mass_pct = self.word_cache_pct\n",
    "                predictor_mass_pct -= mass_pct\n",
    "                predictions += (\n",
    "                    mass_pct\n",
    "                    * self.word_cache\n",
    "                    / self.word_cache.sum(dim=1, keepdim=True)\n",
    "                )\n",
    "\n",
    "            if self.unif_smoothing:\n",
    "                # Uniform smoothing enabled\n",
    "                mass_pct = self.unif_smoothing\n",
    "                predictor_mass_pct -= mass_pct\n",
    "                predictions += (\n",
    "                    mass_pct * torch.ones_like(predictor_dist) / self.vocab_size\n",
    "                )\n",
    "\n",
    "            if self.kn5_pct:\n",
    "                # KN5 model interpolation\n",
    "                mass_pct = self.kn5_pct\n",
    "                predictor_mass_pct -= mass_pct\n",
    "                predictions += (\n",
    "                    mass_pct * self.kn5_distr[loader.batch_sampler.batch_idxs, :]\n",
    "                )\n",
    "\n",
    "        predictions += predictor_mass_pct * predictor_dist\n",
    "        ll = (labels_one_hot * torch.log(predictions)).sum(dim=[0, 1])\n",
    "        interp_loss = -ll  # sum negative log likelihood\n",
    "\n",
    "        return interp_loss.item()\n",
    "\n",
    "    def _do_prediction(\n",
    "        self, inputs, pred_targets, pcounts, train=False, batch_idx=0, loader=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Do prediction.\n",
    "        \"\"\"\n",
    "        class_predictions = correct_arr = None\n",
    "        #print('sef.predictor', self.predictor)\n",
    "        if self.predictor:\n",
    "\n",
    "            predictor_dist, predictor_logits = self.predictor(inputs.detach())\n",
    "\n",
    "            # This loss is without inference-time model interpolation\n",
    "            #print('predictor_logits, pred_targets line 525',predictor_logits.shape,' ',pred_targets.shape)\n",
    "            \n",
    "            pred_loss = self.predictor_loss(\n",
    "                torch.squeeze(predictor_logits), torch.squeeze(pred_targets)\n",
    "            )  # cross-entropy loss\n",
    "            \n",
    "            #print('pred_loss ',pred_loss)\n",
    "            # This loss is for the interpolated model\n",
    "            interp_loss = self._interpolated_loss(\n",
    "                predictor_dist, pred_targets, loader=loader, train=train\n",
    "            )\n",
    "\n",
    "            _, class_predictions = torch.max(predictor_dist, 1)\n",
    "            pcounts[\"total_samples\"] += pred_targets.size(0)\n",
    "            correct_arr = class_predictions == pred_targets\n",
    "            pcounts[\"correct_samples\"] += correct_arr.sum().item()\n",
    "            pred_loss_ = pred_loss.item()\n",
    "            pcounts[\"total_pred_loss\"] += pred_loss_\n",
    "            pcounts[\"total_interp_loss\"] += interp_loss\n",
    "            if train:\n",
    "                # Predictor backward + optimize\n",
    "                pred_loss.backward()\n",
    "                self.pred_optimizer.step()\n",
    "\n",
    "        if self.batch_log_interval and batch_idx % self.batch_log_interval == 0:\n",
    "            print(\"Finished batch %d\" % batch_idx)\n",
    "            if self.predictor:\n",
    "                batch_acc = correct_arr.float().mean() * 100\n",
    "                batch_ppl = lang_util.perpl(pred_loss_ / pred_targets.size(0))\n",
    "                print(\n",
    "                    \"Partial pred acc - \"\n",
    "                    \"batch acc: %.3f%%, pred ppl: %.1f\" % (batch_acc, batch_ppl)\n",
    "                )\n",
    "\n",
    "        return (pcounts, class_predictions, correct_arr)\n",
    "\n",
    "    def _compute_loss(self, predicted_outputs, targets):\n",
    "        \"\"\"\n",
    "        Compute loss across multiple layers (if applicable).\n",
    "\n",
    "        First layer loss (l1_loss) is between last image prediction and actual input\n",
    "            image\n",
    "        Layers > 1 loss (ls_loss) is between last output (hidden predictions) and\n",
    "            actual hidden\n",
    "\n",
    "        Args:\n",
    "            - predicted_outputs: list of len n_layers of (bsz, d_in or total_cells)\n",
    "            - targets: 2-tuple\n",
    "                - list of actual_input (bsz, d_in) by layer\n",
    "                - list of x_b (bsz, total_cells)) by layer\n",
    "\n",
    "        Note that batch size will differ if using a smaller first epoch batch size.\n",
    "        In this case we crop target tensors to match predictions.\n",
    "\n",
    "        TODO: Decision to be made on whether to compute loss vs max-pooled column\n",
    "        activations or cells.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if predicted_outputs is not None:\n",
    "\n",
    "            # TODO: We can stack these and run loss once only\n",
    "            if self.loss_layers in [\"first\", \"all_layers\"]:\n",
    "                bottom_targets = targets[0].detach()\n",
    "                pred_img = predicted_outputs[0]\n",
    "                #print('pred_img at 590', pred_img.shape)\n",
    "                #print('bottom_targets at 591', bottom_targets.shape)\n",
    "                l1_loss = self.loss(pred_img, bottom_targets)\n",
    "                if loss is None:\n",
    "                    loss = l1_loss\n",
    "                else:\n",
    "                    loss += l1_loss\n",
    "\n",
    "            if self.n_layers > 1 and self.loss_layers in [\"above_first\", \"all_layers\"]:\n",
    "                memory = self._repackage_hidden(targets[1])\n",
    "                for l in range(self.n_layers - 1):\n",
    "                    higher_targets = memory[\n",
    "                        l\n",
    "                    ]  # Target memory states up to 2nd to last layer\n",
    "                    outputs = predicted_outputs[l + 1]  # Predictions from layer above\n",
    "                    ls_loss = self.loss(outputs, higher_targets)\n",
    "                    if loss is None:\n",
    "                        loss = ls_loss\n",
    "                    else:\n",
    "                        loss += ls_loss\n",
    "\n",
    "            if self.l2_reg and self.lateral_conn:\n",
    "                for l in self.model.children():\n",
    "                    # Add L2 reg term for recurrent weights\n",
    "                    loss += self.l2_reg * l.linear_b.weight.norm(2) ** 2\n",
    "                    if hasattr(l.linear_b, \"bias\"):\n",
    "                        loss += self.l2_reg * l.linear_b.bias.norm(2) ** 2\n",
    "            if self.dec_l2_reg:\n",
    "                for l in self.model.children():\n",
    "                    # Add L2 reg term for decode weights\n",
    "                    loss += self.dec_l2_reg * l.linear_d.weight.norm(2) ** 2\n",
    "                    if hasattr(l.linear_d, \"bias\") and l.linear_d.bias is not None:\n",
    "                        loss += self.dec_l2_reg * l.linear_d.bias.norm(2) ** 2\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_epoch(self, epoch, loader=None):\n",
    "        ret = {}\n",
    "        print(\"Evaluating...\")\n",
    "        if not loader:\n",
    "            loader = self.val_loader\n",
    "\n",
    "        if self.instrumentation:\n",
    "            # Capture entropy prior to evaluation\n",
    "            _, train_entropy = binary_entropy(self.model.RSM_1.duty_cycle)\n",
    "            ret[\"train_entropy\"] = train_entropy.item()\n",
    "            self.model.RSM_1.duty_cycle.fill_(0.0)  # Clear duty cycle\n",
    "\n",
    "        self.model.eval()\n",
    "        if self.predictor:\n",
    "            self.predictor.eval()\n",
    "\n",
    "        if self.weight_sparsity is not None:\n",
    "            # Rezeroing happens before forward pass, so rezero after last\n",
    "            # training forward.\n",
    "            self.model._zero_sparse_weights()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            pcounts = {\n",
    "                \"total_samples\": 0.0,\n",
    "                \"correct_samples\": 0.0,\n",
    "                \"total_pred_loss\": 0.0,\n",
    "                \"total_interp_loss\": 0.0,\n",
    "            }\n",
    "            print(self.eval_batch_size)#debug\n",
    "            hidden = self._init_hidden(self.eval_batch_size)\n",
    "\n",
    "            read_out_tgt = []\n",
    "            read_out_pred = []\n",
    "            metrics = {}\n",
    "\n",
    "            for _b_idx, (inputs, targets, pred_targets, input_labels) in enumerate(\n",
    "                loader\n",
    "            ):\n",
    "\n",
    "                # Forward\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                pred_targets = pred_targets.to(self.device)\n",
    "                input_labels = input_labels.to(self.device)\n",
    "\n",
    "                self._cache_inputs(input_labels, clear=_b_idx == 0)\n",
    "                \n",
    "\n",
    "\n",
    "                output, hidden = self.model(inputs, hidden)\n",
    "                \n",
    "                x_b, pred_input = self._get_prediction_and_loss_inputs(hidden)\n",
    "\n",
    "                # Loss\n",
    "                #print('output shape ', output)\n",
    "                loss = self._compute_loss(output, (targets, x_b))\n",
    "                if loss is not None:\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                pcounts, class_predictions, correct_arr = self._do_prediction(\n",
    "                    pred_input, pred_targets, pcounts, batch_idx=_b_idx, loader=loader\n",
    "                )\n",
    "\n",
    "                self._read_out_predictions(\n",
    "                    pred_targets, class_predictions, read_out_tgt, read_out_pred\n",
    "                )\n",
    "\n",
    "                hidden = self._repackage_hidden(hidden)\n",
    "\n",
    "                if self.instrumentation:\n",
    "                    metrics = self._agg_batch_metrics(\n",
    "                        metrics,\n",
    "                        pred_images=output[0].unsqueeze(0),\n",
    "                        targets=targets.unsqueeze(0),\n",
    "                        correct_arr=correct_arr.unsqueeze(0),\n",
    "                        pred_targets=pred_targets,\n",
    "                        class_predictions=class_predictions,\n",
    "                    )\n",
    "\n",
    "            if self.instrumentation:\n",
    "                # Save some snapshots from last batch of epoch\n",
    "                # if self.model_kind == \"rsm\":\n",
    "                #     metrics['last_hidden_snp'] = x_b\n",
    "                #     metrics['last_input_snp'] = inputs\n",
    "                #     metrics['last_output_snp'] = last_output\n",
    "\n",
    "                # After all eval batches, generate stats & figures\n",
    "                ret.update(self._generate_instr_charts(metrics))\n",
    "                ret.update(self._store_instr_hists())\n",
    "                _, test_entropy = binary_entropy(self.model.RSM_1.duty_cycle)\n",
    "                ret[\"test_entropy\"] = test_entropy.item()\n",
    "                self.model.RSM_1.duty_cycle.fill_(0.0)  # Clear duty cycle\n",
    "\n",
    "            num_batches = _b_idx + 1\n",
    "            num_samples = pcounts[\"total_samples\"]\n",
    "            ret[\"val_loss\"] = val_loss = total_loss / num_batches\n",
    "            if self.predictor:\n",
    "                test_pred_loss = pcounts[\"total_pred_loss\"] / num_samples\n",
    "                test_interp_loss = pcounts[\"total_interp_loss\"] / num_samples\n",
    "                ret[\"val_interp_ppl\"] = lang_util.perpl(test_interp_loss)\n",
    "                ret[\"val_pred_ppl\"] = lang_util.perpl(test_pred_loss)\n",
    "                ret[\"val_pred_acc\"] = 100 * pcounts[\"correct_samples\"] / num_samples\n",
    "\n",
    "            if not self.best_val_loss or val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "            else:\n",
    "                # Val loss increased\n",
    "                if self.learning_rate_gamma:\n",
    "                    self.do_anneal_learning = True  # Reduce LR during post_epoch\n",
    "                if self.pause_after_upticks and not self.model_learning_paused:\n",
    "                    if not self.pause_min_epoch or (\n",
    "                        self.pause_min_epoch and epoch >= self.pause_min_epoch\n",
    "                    ):\n",
    "                        self.n_upticks += 1\n",
    "                        if self.n_upticks >= self.pause_after_upticks:\n",
    "                            print(\n",
    "                                \">>> Pausing learning after %d upticks, validation \"\n",
    "                                \"loss rose to %.3f, best: %.3f\"\n",
    "                                % (self.n_upticks, val_loss, self.best_val_loss)\n",
    "                            )\n",
    "                            self._pause_learning(epoch)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _pause_learning(self, epoch):\n",
    "        print(\n",
    "            \"Pausing learning... Setting eval interval to %d\" % self.pause_eval_interval\n",
    "        )\n",
    "        self.model_learning_paused = True\n",
    "        self.eval_interval = self.pause_eval_interval\n",
    "        self.model._zero_kwinner_boost()\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"\n",
    "        Do one epoch of training and testing.\n",
    "\n",
    "        Returns:\n",
    "            A dict that describes progress of this epoch.\n",
    "            The dict includes the key 'stop'. If set to one, this network\n",
    "            should be stopped early. Training is not progressing well enough.\n",
    "        \"\"\"\n",
    "        t1 = time.time()\n",
    "        ret = {}\n",
    "\n",
    "        self.model.train()  # Needed if using dropout\n",
    "        \n",
    "        if self.predictor:\n",
    "            self.predictor.train()\n",
    "\n",
    "        # Performance metrics\n",
    "        total_loss = 0.0\n",
    "        pcounts = {\n",
    "            \"total_samples\": 0.0,\n",
    "            \"correct_samples\": 0.0,\n",
    "            \"total_pred_loss\": 0.0,\n",
    "            \"total_interp_loss\": 0.0,\n",
    "        }\n",
    "\n",
    "        bsz = self.batch_size\n",
    "\n",
    "        hidden = self.train_hidden_buffer[-1] if self.train_hidden_buffer else None\n",
    "        if hidden is None:\n",
    "            hidden = self._init_hidden(self.batch_size)\n",
    "        i = 1\n",
    "        for batch_idx, (inputs, targets, pred_targets, _input_labels) in enumerate(\n",
    "            self.train_loader\n",
    "        ):\n",
    "           \n",
    "\n",
    "            # Inputs are of shape (batch, input_size)\n",
    "            if inputs.size(0) > bsz:\n",
    "                # Crop to smaller first epoch batch size\n",
    "                inputs = inputs[:bsz]\n",
    "                targets = targets[:bsz]\n",
    "                pred_targets = pred_targets[:bsz]\n",
    "\n",
    "            hidden = self._repackage_hidden(hidden) #detach from computational graph\n",
    "            \n",
    "            self.optimizer.zero_grad() #zero out th\n",
    "            if self.pred_optimizer:\n",
    "                self.pred_optimizer.zero_grad()\n",
    "\n",
    "            inputs = inputs.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "            pred_targets = pred_targets.to(self.device)\n",
    "            \n",
    "            output, hidden = self.model(inputs, hidden)\n",
    "            \n",
    "\n",
    "            x_b, pred_input = self._get_prediction_and_loss_inputs(hidden)\n",
    "\n",
    "            self.train_hidden_buffer.append(hidden)\n",
    "\n",
    "            loss_targets = (targets, x_b)\n",
    "            #print('output at line 851',output[0].shape)\n",
    "            loss = self._compute_loss(output, loss_targets)\n",
    "            if loss is not None:\n",
    "                total_loss += loss.item()\n",
    "                if not self.model_learning_paused:\n",
    "                    self._backward_and_optimize(loss)        \n",
    "\n",
    "            # Keep only latest batch states around\n",
    "            self.train_hidden_buffer = self.train_hidden_buffer[-1:]\n",
    "            \n",
    "            \n",
    "            #print('now do prediction line 857')\n",
    "            pcounts, class_predictions, correct_arr = self._do_prediction(\n",
    "                pred_input,\n",
    "                pred_targets, #pred_targets\n",
    "                pcounts,\n",
    "                train=True,\n",
    "                batch_idx=batch_idx,\n",
    "                loader=self.train_loader,\n",
    "            )\n",
    "\n",
    "            if epoch == 0 and batch_idx >= self.batches_in_first_epoch - 1:\n",
    "                print(\n",
    "                    \"Breaking after %d batches in epoch %d\"\n",
    "                    % (self.batches_in_first_epoch, epoch)\n",
    "                )\n",
    "                break\n",
    "\n",
    "        ret[\"stop\"] = 0\n",
    "        self.model._post_train_epoch(epoch)  # Update kwinners duty cycles, etc\n",
    "\n",
    "        if self.eval_interval and (epoch - 1) % self.eval_interval == 0:\n",
    "\n",
    "            # Evaluate each x epochs\n",
    "            ret.update(self.eval_epoch(epoch))\n",
    "\n",
    "        train_time = time.time() - t1\n",
    "        self._post_epoch(epoch)\n",
    "\n",
    "        num_batches = batch_idx + 1\n",
    "        ret[\"train_loss\"] = total_loss / num_batches\n",
    "        if self.predictor:\n",
    "            num_samples = num_batches * self.batch_size\n",
    "            train_pred_loss = pcounts[\"total_pred_loss\"] / num_samples\n",
    "            train_interp_loss = pcounts[\"total_interp_loss\"] / num_samples\n",
    "            ret[\"train_interp_ppl\"] = lang_util.perpl(train_interp_loss)\n",
    "            ret[\"train_pred_ppl\"] = lang_util.perpl(train_pred_loss)\n",
    "            ret[\"train_pred_acc\"] = (\n",
    "                100 * pcounts[\"correct_samples\"] / pcounts[\"total_samples\"]\n",
    "            )\n",
    "\n",
    "        ret[\"epoch_time_train\"] = train_time\n",
    "        ret[\"epoch_time\"] = time.time() - t1\n",
    "        ret[\"learning_rate\"] = self.learning_rate\n",
    "        print(epoch, print_epoch_values(ret))\n",
    "        return ret\n",
    "\n",
    "    def _post_epoch(self, epoch):\n",
    "        \"\"\"\n",
    "        The set of actions to do after each epoch of training: adjust learning\n",
    "        rate, rezero sparse weights, and update boost strengths.\n",
    "        \"\"\"\n",
    "        if self.pause_after_epochs and epoch == self.pause_after_epochs:\n",
    "            self._pause_learning(epoch)\n",
    "        self._adjust_learning_rate(epoch)\n",
    "        if self.eval_interval_schedule:\n",
    "            for step, new_interval in self.eval_interval_schedule:\n",
    "                if step == epoch:\n",
    "                    print(\">> Changing eval interval to %d\" % new_interval)\n",
    "                    self.eval_interval = new_interval\n",
    "\n",
    "    def model_save(self, checkpoint_dir):\n",
    "        \"\"\"Save the model in this directory.\n",
    "\n",
    "        :param checkpoint_dir:\n",
    "\n",
    "        :return: str: The return value is expected to be the checkpoint path that\n",
    "        can be later passed to `model_restore()`.\n",
    "\n",
    "        NOTE: Embedding is not saved with model, so results may vary if a different\n",
    "        embedding binary (even if re-generated with same config) is used with the\n",
    "        restored model.\n",
    "        \"\"\"\n",
    "        checkpoint_file = os.path.join(checkpoint_dir, self.model_filename)\n",
    "        if checkpoint_file.endswith(\".pt\"):\n",
    "            torch.save(self.model, checkpoint_file)\n",
    "        else:\n",
    "            torch.save(self.model.state_dict(), checkpoint_file)\n",
    "        if self.predictor:\n",
    "            checkpoint_file = os.path.join(checkpoint_dir, self.pred_model_filename)\n",
    "            if checkpoint_file.endswith(\".pt\"):\n",
    "                torch.save(self.predictor, checkpoint_file)\n",
    "            else:\n",
    "                torch.save(self.predictor.state_dict(), checkpoint_file)\n",
    "\n",
    "        if self.save_onnx_graph_at_checkpoint:\n",
    "            dummy_input = (torch.rand(1, 1, 28, 28),)\n",
    "            torch.onnx.export(\n",
    "                self.model, dummy_input, self.graph_filename, verbose=True\n",
    "            )\n",
    "\n",
    "        return checkpoint_file\n",
    "\n",
    "    def model_restore(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        :param checkpoint_path: Loads model from this checkpoint path.\n",
    "        If path is a directory, will append the parameter model_filename\n",
    "        \"\"\"\n",
    "        print(\"Loading from\", checkpoint_path)\n",
    "        checkpoint_file = os.path.join(checkpoint_path, self.model_filename)\n",
    "        if checkpoint_file.endswith(\".pt\"):\n",
    "            self.model = torch.load(checkpoint_file, map_location=self.device)\n",
    "        else:\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(checkpoint_file, map_location=self.device)\n",
    "            )\n",
    "        checkpoint_file = os.path.join(checkpoint_path, self.pred_model_filename)\n",
    "        if checkpoint_file.endswith(\".pt\"):\n",
    "            self.predictor = torch.load(checkpoint_file, map_location=self.device)\n",
    "        else:\n",
    "            self.predictor.load_state_dict(\n",
    "                torch.load(checkpoint_file, map_location=self.device)\n",
    "            )\n",
    "        return self.model\n",
    "\n",
    "    def model_cleanup(self):\n",
    "        pass\n",
    "\n",
    "    def _agg_batch_metrics(self, metrics, **kwargs):\n",
    "        for metric_key, val in kwargs.items():\n",
    "            if val is not None:\n",
    "                if metric_key not in metrics:\n",
    "                    metrics[metric_key] = val\n",
    "                else:\n",
    "                    current = metrics[metric_key]\n",
    "                    metrics[metric_key] = torch.cat((current, val))\n",
    "        return metrics\n",
    "\n",
    "    def _generate_instr_charts(self, metrics):\n",
    "        ret = {}\n",
    "        if self.model_kind == \"rsm\" and self.instrumentation:\n",
    "\n",
    "            if \"img_preds\" in self.instr_charts:\n",
    "                ret[\"img_preds\"] = self._image_grid(\n",
    "                    metrics[\"pred_images\"],\n",
    "                    compare_with=metrics[\"targets\"],\n",
    "                    compare_correct=metrics[\"correct_arr\"],\n",
    "                ).cpu()\n",
    "\n",
    "            if \"img_memory_snapshot\" in self.instr_charts and self.n_layers > 1:\n",
    "                last_inp_layers = [None for x in range(self.n_layers)]\n",
    "                last_inp_layers[0] = metrics[\"last_input_snp\"]\n",
    "                fig = plot_tensors(\n",
    "                    self.model,\n",
    "                    [\n",
    "                        (\"last_out\", metrics[\"last_output_snp\"]),\n",
    "                        (\"inputs\", last_inp_layers),\n",
    "                        (\"x_b\", metrics[\"last_hidden_snp\"]),\n",
    "                    ],\n",
    "                    return_fig=True,\n",
    "                )\n",
    "                ret[\"img_memory_snapshot\"] = fig2img(fig)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _read_out_predictions(\n",
    "        self,\n",
    "        pred_targets,\n",
    "        class_predictions,\n",
    "        read_out_tgt,\n",
    "        read_out_pred,\n",
    "        read_out_len=20,\n",
    "    ):\n",
    "        if self.predictor and self.corpus and len(read_out_tgt) < read_out_len:\n",
    "            read_out_tgt.append(pred_targets[0])\n",
    "            read_out_pred.append(class_predictions[0])\n",
    "            \n",
    "\n",
    "            if len(read_out_tgt) == read_out_len:\n",
    "                print_aligned_sentences(\n",
    "                    self.corpus.read_out(read_out_tgt),\n",
    "                    self.corpus.read_out(read_out_pred),\n",
    "                    labels=[\"Targ\", \"Pred\"],\n",
    "                )\n",
    "                \n",
    "    def _reward_out_predictions(\n",
    "        self,\n",
    "        pred_targets,\n",
    "        class_predictions,\n",
    "        read_out_tgt,\n",
    "        read_out_pred,\n",
    "        read_out_len=20,\n",
    "    ):\n",
    "        \n",
    "        if pred_targets[0].item() == class_predictions[0].item():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def _store_instr_hists(self):\n",
    "        ret = {}\n",
    "        if self.instrumentation:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if \"weight\" in name or \"decay\" in name or \"ramp\" in name:\n",
    "                    data = param.data.cpu()\n",
    "                    if data.size(0):\n",
    "                        ret[\"hist_\" + name] = data\n",
    "                        if self.debug:\n",
    "                            print(\n",
    "                                \"%s: mean: %.3f std: %.3f\"\n",
    "                                % (name, data.mean(), data.std())\n",
    "                            )\n",
    "        return ret\n",
    "\n",
    "    def _store_activity_for_viz(self, x_bs, input_labels, pred_labels):\n",
    "        \"\"\"\n",
    "        Aggregate activity for a supplied batch\n",
    "        \"\"\"\n",
    "        for _x_b, label, target in zip(x_bs, input_labels, pred_labels):\n",
    "            _label = label.item()\n",
    "            _label_next = target.item()\n",
    "            activity = _x_b.detach().view(self.m_groups, -1).squeeze()\n",
    "            key = \"%d-%d\" % (_label, _label_next)\n",
    "            if key not in self.activity_by_inputs:\n",
    "                self.activity_by_inputs[key] = []\n",
    "            self.activity_by_inputs[key].append(activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class RsmAttEnv(gym.Env):\n",
    "    \"\"\"This is rsm attention environment\"\"\"\n",
    "    \n",
    "    def __init__(self, config_model = {}, epoch = 1):\n",
    "        super(RsmAttEnv, self).__init__()\n",
    "        # There are two configs: config_env for environment, and config_model for model to be reset\n",
    "        print(\"Environment initalized...\")            \n",
    "        print(\"Using torch version\", torch.__version__)\n",
    "        print(\"Torch device count=%d\" % torch.cuda.device_count())\n",
    "        \n",
    "        self.epoch = epoch\n",
    "\n",
    "        self.exp = RSMExperiment(config_model)\n",
    "        self.exp.model_setup(config_model)\n",
    "        #self._build_dataloader()\n",
    "        self.cur_step = 0\n",
    "        \n",
    "        #set up model\n",
    "\n",
    "        self.batch_size = config_model.get(\"batch_size\", self.exp.batch_size)\n",
    "        self.eval_batch_size = config_model.get(\"eval_batch_size\", self.exp.eval_batch_size)\n",
    "        self.batches_in_epoch = config_model.get(\"batches_in_epoch\", self.exp.batches_in_epoch)\n",
    "        self.eval_batches_in_epoch = config_model.get(\n",
    "            \"eval_batches_in_epoch\", self.batches_in_epoch\n",
    "        )\n",
    "        self.data_dir = config_model.get(\"data_dir\", \"data\")\n",
    "        self.embedding_kind = config_model.get(\"embedding_kind\", \"ptb_fasttext_e5\")\n",
    "        self.m_groups = config_model.get(\"m_groups\", self.exp.m_groups)\n",
    "        self.embed_dim = config_model.get(\"embed_dim\", self.exp.embed_dim)\n",
    "        \n",
    "        #self.action_space = spaces.Discrete(4**self.heads) #4**heads\n",
    "        self.action_space = spaces.Discrete(4**1)\n",
    "        self.x, self.x_b = self._init_state()\n",
    "        #print('self.total_cells at 227 rsm_att',self.total_cells)\n",
    "        max_val = sys.maxsize\n",
    "        \n",
    "        self.obs_x = spaces.Box(low=-3,\n",
    "                                high=3, \n",
    "                                shape=(self.batch_size, self.embed_dim),\n",
    "                                dtype=np.float64)\n",
    "        self.obs_x_b = spaces.Box(low=-3,\n",
    "                                  high=3,\n",
    "                                  shape=(self.batch_size, self.m_groups),\n",
    "                                  dtype=np.float64)\n",
    "        \n",
    "        self.observation_space = spaces.Tuple([self.obs_x, self.obs_x_b])\n",
    "        \n",
    "        self.hidden = self.exp._init_hidden(self.batch_size)\n",
    "        self.batch_idx = 0 #this is the current_step check, if the batch_idx equal datasets size then training is done\n",
    "        self.done = False\n",
    "        self.get_one = iter(self.exp.train_loader)\n",
    "        self.reward = 0        \n",
    "        print('Environment created!')\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_idx = 0 \n",
    "        self.exp = RSMExperiment(config_model)\n",
    "        self.exp.model_setup(config_model)\n",
    "        self.x, self.x_b = self._init_state()\n",
    "        max_val = sys.maxsize\n",
    "        \n",
    "        self.obs_x = spaces.Box(low=-3,\n",
    "                                high=3, \n",
    "                                shape=(self.batch_size, self.embed_dim),\n",
    "                                dtype=np.float64)\n",
    "        \n",
    "        self.obs_x_b = spaces.Box(low=-3,\n",
    "                                  high=3,\n",
    "                                  shape=(self.batch_size, self.m_groups),\n",
    "                                  dtype=np.float64)\n",
    "        \n",
    "        self.observation_space = spaces.Tuple([self.obs_x, self.obs_x_b])\n",
    "        \n",
    "        self.hidden = self.exp._init_hidden(self.batch_size)\n",
    "        self.done = False\n",
    "        self.get_one = iter(self.exp.train_loader)\n",
    "        self.reward = 0\n",
    "        print(\"Environment reset!\")   \n",
    "        return \n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        \n",
    "        self.exp.model.train() #telling model that we are training\n",
    "        t1 = time.time()\n",
    "        ret = {}\n",
    "\n",
    "        self.exp.model.train()  # Needed if using dropout\n",
    "        \n",
    "        if self.exp.predictor:\n",
    "            self.exp.predictor.train()\n",
    "\n",
    "        # Performance metrics\n",
    "        total_loss = 0.0\n",
    "        pcounts = {\n",
    "            \"total_samples\": 0.0,\n",
    "            \"correct_samples\": 0.0,\n",
    "            \"total_pred_loss\": 0.0,\n",
    "            \"total_interp_loss\": 0.0,\n",
    "        }\n",
    "        \n",
    "        bsz = self.batch_size\n",
    "\n",
    "        if self.hidden is None:\n",
    "            self.hidden = self.exp._init_hidden(self.batch_size)\n",
    "\n",
    "        if self.batch_idx == len(self.exp.train_loader) - 1:\n",
    "            self.done = True\n",
    "        else:\n",
    "            self.batch_idx+=1\n",
    "            \n",
    "        inputs, targets, pred_targets, _input_labels = self.get_one.next() #getdata to train  \n",
    "        \n",
    "        if inputs.size(0) > bsz:\n",
    "                # Crop to smaller first epoch batch size\n",
    "                inputs = inputs[:bsz]\n",
    "                targets = targets[:bsz]\n",
    "                pred_targets = pred_targets[:bsz]\n",
    "\n",
    "        self.hidden = self.exp._repackage_hidden(self.hidden) #detach from computational graph\n",
    "        \n",
    "        pre_inputs = inputs\n",
    "        \n",
    "        action = list(f'{action:0{2*1}b}') \n",
    "        action = [int(i) for i in action] \n",
    "        #convert action from one integer i.e. 15 to list of tuples of binary [(1,0),(1,1)]\n",
    "\n",
    "        iter_action = iter(action) #[1,0,1,0] => [(1,0),(1,0)]\n",
    "        \n",
    "        action_heads = list(zip(iter_action,iter_action))\n",
    "\n",
    "        for act in range(len(action_heads)):\n",
    "            \n",
    "            inputs = action_heads[act][0]*inputs\n",
    "\n",
    "\n",
    "        self.exp.optimizer.zero_grad() #zero out th\n",
    "        \n",
    "        if self.exp.pred_optimizer:\n",
    "            self.exp.pred_optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        inputs = inputs.to(self.exp.device)\n",
    "        targets = targets.to(self.exp.device)\n",
    "        pred_targets = pred_targets.to(self.exp.device)\n",
    "\n",
    "        output, self.hidden = self.exp.model(inputs, self.hidden)\n",
    "\n",
    "        self.x_b, pred_input = self.exp._get_prediction_and_loss_inputs(self.hidden)\n",
    "\n",
    "        self.exp.train_hidden_buffer.append(self.hidden)\n",
    "\n",
    "        loss_targets = (targets, self.x_b)\n",
    "        #print('output at line 851',output[0].shape)\n",
    "        loss = self.exp._compute_loss(output, loss_targets)\n",
    "        if loss is not None:\n",
    "            total_loss += loss.item()\n",
    "            if not self.exp.model_learning_paused:\n",
    "                self.exp._backward_and_optimize(loss)        \n",
    "\n",
    "        # Keep only latest batch states around\n",
    "        self.exp.train_hidden_buffer = self.exp.train_hidden_buffer[-1:]\n",
    "\n",
    "        pcounts, class_predictions, correct_arr = self.exp._do_prediction(\n",
    "            pred_input,\n",
    "            pred_targets, #pred_targets\n",
    "            pcounts,\n",
    "            train=True,\n",
    "            batch_idx=self.batch_idx,\n",
    "            loader=self.exp.train_loader,\n",
    "        )\n",
    "\n",
    "        ret[\"stop\"] = 0\n",
    "        \n",
    "        self.exp.model._post_train_epoch(self.epoch)  # Update kwinners duty cycles, etc\n",
    "        \n",
    "        read_out_tgt = []\n",
    "        read_out_pred = []\n",
    "        metrics = {}\n",
    "        \n",
    "        self.reward += self.exp._reward_out_predictions(\n",
    "                    pred_targets, class_predictions, read_out_tgt, read_out_pred\n",
    "                )\n",
    "        if self.done:\n",
    "            print('rewards value of epoch {} is {}'.format(self.epoch,self.reward))\n",
    "            \n",
    "        #TODOL: reward should be a list of dictionary for each step\n",
    "        x_b = self.hidden[0][0].reshape(self.batch_size,-1)\n",
    "        obs = [pre_inputs, x_b]\n",
    "        return obs, self.reward, self.done #self.info\n",
    "    \n",
    "    def _build_dataloader(self):\n",
    "        \n",
    "        \"\"\"Data Loader should be initiated once,\n",
    "        Leave it here we can adjust it later\"\"\"\n",
    "        \n",
    "        self.val_loader = self.corpus = None\n",
    "\n",
    "        # Download \"Penn Treebank\" dataset\n",
    "        from torchnlp.datasets import penn_treebank_dataset\n",
    "\n",
    "        print(\"Maybe download PTB...\")\n",
    "        penn_treebank_dataset(self.data_dir + \"/PTB\", train=True, test=True)\n",
    "        corpus = lang_util.Corpus(self.data_dir + \"/PTB\")\n",
    "        train_sampler = PTBSequenceSampler(\n",
    "            corpus.train,\n",
    "            batch_size=self.batch_size,\n",
    "            max_batches=self.batches_in_epoch,\n",
    "        )\n",
    "\n",
    "        import fasttext\n",
    "\n",
    "        # Generated via notebooks/ptb_embeddings.ipynb\n",
    "        embedding = {}\n",
    "        ft_model = fasttext.load_model(\n",
    "            self.data_dir + \"/embeddings/%s.bin\" % self.embedding_kind\n",
    "        )\n",
    "        for word_id, word in enumerate(corpus.dictionary.idx2word):\n",
    "            embedding[word_id] = torch.tensor(ft_model[word])\n",
    "\n",
    "        if self.embedding_kind:\n",
    "            print(\n",
    "                \"Loaded embedding dict (%s) with %d entries\"\n",
    "                % (self.embedding_kind, len(embedding))\n",
    "            )\n",
    "\n",
    "        collate_fn = partial(ptb_pred_sequence_collate, vector_dict=embedding)\n",
    "        self.train_loader = DataLoader(\n",
    "            corpus.train, batch_sampler=train_sampler, collate_fn=collate_fn\n",
    "        )\n",
    "        val_sampler = PTBSequenceSampler(\n",
    "            corpus.test,\n",
    "            batch_size=self.eval_batch_size,\n",
    "            max_batches=self.eval_batches_in_epoch,\n",
    "            uniform_offsets=True,\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            corpus.test, \n",
    "            batch_sampler=val_sampler, \n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        self.corpus = corpus\n",
    "        print(\"Built dataloaders...\")\n",
    "        \n",
    "    def _init_state(self):\n",
    "        x_b = torch.zeros((self.batch_size, \n",
    "                           self.m_groups), \n",
    "                          dtype=torch.float32, \n",
    "                          requires_grad=False) #before d_in it was tc #2 is number of heads\n",
    "        x = torch.zeros((self.batch_size, \n",
    "                        self.embed_dim), \n",
    "                          dtype=torch.float32, \n",
    "                          requires_grad=False) #before d_in it was tc #2 is number of heads\n",
    "        return x, x_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initalized...\n",
      "Using torch version 1.4.0\n",
      "Torch device count=0\n",
      "setup: Using cpu\n",
      "Maybe download PTB...\n",
      "Loaded embedding dict (ptb_fasttext_e5) with 10000 entries\n",
      "Built dataloaders...\n",
      "Created <RSMLayer m=60 n=1 k=7 d_in=100 eps=0.50 /> with 15760 trainable params\n",
      "Created RSMNet with 1 layer(s)\n",
      "Environment created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_model = {\n",
    "    \"data_dir\": os.path.expanduser(\"~/nta/datasets\"),\n",
    "    \"path\": os.path.expanduser(\"~/nta/results\"),\n",
    "}\n",
    "env = RsmAttEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[ 0.0397, -0.3821,  0.4202,  ...,  0.3019, -0.0484,  0.1362],\n",
       "          [-0.1922, -0.1014,  0.3861,  ..., -0.3230,  0.0634,  0.1617],\n",
       "          [ 0.1360, -0.0353,  0.2040,  ...,  0.0354,  0.2955, -0.0813],\n",
       "          ...,\n",
       "          [-0.1963, -0.3011,  0.4417,  ...,  0.0221,  0.2005,  0.0226],\n",
       "          [-0.6475,  0.2050,  0.3260,  ...,  0.0362, -0.0282,  0.4589],\n",
       "          [ 0.2003,  0.2507,  0.2764,  ..., -0.2628, -0.1686, -0.0167]]),\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ViewBackward>)],\n",
       " 0,\n",
       " False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-01 00:44:00,266\tINFO resource_spec.py:212 -- Starting Ray with 8.64 GiB memory available for workers and up to 4.32 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-08-01 00:44:00,493\tWARNING services.py:923 -- Redis failed to start, retrying now.\n",
      "2020-08-01 00:44:00,756\tINFO services.py:1165 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "2020-08-01 00:44:01,049\tWARNING deprecation.py:30 -- DeprecationWarning: `sample_batch_size` has been deprecated. Use `rollout_fragment_length` instead. This will raise an error in the future!\n",
      "2020-08-01 00:44:01,062\tWARNING deprecation.py:30 -- DeprecationWarning: `use_pytorch` has been deprecated. Use `framework=torch` instead. This will raise an error in the future!\n",
      "2020-08-01 00:44:01,063\tWARNING deprecation.py:30 -- DeprecationWarning: `eager` has been deprecated. Use `framework=tfe` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initalized...\n",
      "Using torch version 1.4.0\n",
      "Torch device count=0\n",
      "setup: Using cpu\n",
      "Maybe download PTB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-08-01 00:44:07,245\tWARNING sac_tf_policy.py:52 -- When not using a state-preprocessor with SAC, `fcnet_hiddens` will be set to an empty list! Any hidden layer sizes are defined via `policy_model.hidden_layer_sizes` and `Q_model.hidden_layer_sizes`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding dict (ptb_fasttext_e5) with 10000 entries\n",
      "Built dataloaders...\n",
      "Created <RSMLayer m=60 n=1 k=7 d_in=100 eps=0.50 /> with 15760 trainable params\n",
      "Created RSMNet with 1 layer(s)\n",
      "Environment created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-01 00:44:07,468\tINFO rollout_worker.py:941 -- Built policy map: {'default_policy': <ray.rllib.policy.torch_policy_template.SACTorchPolicy object at 0x7f291bfc3a90>}\n",
      "2020-08-01 00:44:07,468\tINFO rollout_worker.py:942 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.TupleFlatteningPreprocessor object at 0x7f2939e95828>}\n",
      "2020-08-01 00:44:07,469\tINFO rollout_worker.py:413 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f293b03ea90>}\n",
      "2020-08-01 00:44:07,528\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.sac.sac import SACTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.registry import register_env\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "def env_creator(env_config):\n",
    "    return RsmAttEnv()  # return an env instance\n",
    "\n",
    "register_env(\"RsmAtt\", env_creator)\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 1\n",
    "# config[\"num_workers\"] = int(multiprocessing.cpu_count() / 2)\n",
    "config[\"num_workers\"] = 1\n",
    "config[\"eager\"] = False\n",
    "config[\"log_level\"] = \"INFO\"\n",
    "config[\"monitor\"] = True\n",
    "config[\"num_cpus_per_worker\"] = 1\n",
    "config[\"use_pytorch\"] = 1\n",
    "config[\"framework\"] = 'torch'\n",
    "config[\"sample_batch_size\"] = 300\n",
    "trainer = SACTrainer(config=config, env=\"RsmAtt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Environment initalized...\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Using torch version 1.4.0\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Torch device count=0\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m setup: Using cpu\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Maybe download PTB...\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Loaded embedding dict (ptb_fasttext_e5) with 10000 entries\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Built dataloaders...\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Created <RSMLayer m=60 n=1 k=7 d_in=100 eps=0.50 /> with 15760 trainable params\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Created RSMNet with 1 layer(s)\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Environment created!\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m /home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m 2020-08-01 00:44:15,003\tWARNING sac_tf_policy.py:52 -- When not using a state-preprocessor with SAC, `fcnet_hiddens` will be set to an empty list! Any hidden layer sizes are defined via `policy_model.hidden_layer_sizes` and `Q_model.hidden_layer_sizes`.\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m setup: Using cpu\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Maybe download PTB...\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m 2020-08-01 00:44:15,241\tINFO rollout_worker.py:526 -- Generating sample batch of size 300\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-01 00:44:20,964\tINFO trainer.py:494 -- Worker crashed during call to train(). To attempt to continue training without the failed worker, set `'ignore_worker_failures': True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Loaded embedding dict (ptb_fasttext_e5) with 10000 entries\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Built dataloaders...\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Created <RSMLayer m=60 n=1 k=7 d_in=100 eps=0.50 /> with 15760 trainable params\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Created RSMNet with 1 layer(s)\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m Environment reset!\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m 2020-08-01 00:44:20,962\tINFO sampler.py:466 -- Raw obs from env: {0: {'agent0': None}}\n",
      "\u001b[2m\u001b[36m(pid=7634)\u001b[0m 2020-08-01 00:44:20,962\tINFO sampler.py:467 -- Info return from env: {0: {'agent0': None}}\n"
     ]
    },
    {
     "ename": "RayTaskError(ValueError)",
     "evalue": "\u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=7634, ip=192.168.2.9)\n  File \"python/ray/_raylet.pyx\", line 446, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 400, in ray._raylet.execute_task.function_executor\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\", line 1125, in par_iter_next\n    return next(self.local_it)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 263, in gen_rollouts\n    yield self.sample()\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 528, in sample\n    batches = [self.input_reader.next()]\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 59, in next\n    batches = [self.get_data()]\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 164, in get_data\n    item = next(self.rollout_provider)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 489, in _env_runner\n    observation_fn=observation_fn)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 641, in _process_observations\n    policy_id).transform(raw_obs)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\", line 199, in transform\n    self.check_shape(observation)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\", line 62, in check_shape\n    self._obs_space, observation)\nValueError: ('Observation outside expected value range', Tuple(Box(100, 100), Box(100, 60)), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-21d21c7948cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0;34m\"continue training without the failed worker, set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                         \"`'ignore_worker_failures': True`.\")\n\u001b[0;32m--> 497\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow logs messages to propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAX_WORKER_FAILURE_RETRIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRayError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ignore_worker_failures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[1;32m    260\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_train() needs to return a dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_exec_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbefore_train_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m_train_exec_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_train_exec_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mbuild_union\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_pull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mbase_iterator\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar_iter_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Always yield after each round of gets with timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_ids, timeout)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m: \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=7634, ip=192.168.2.9)\n  File \"python/ray/_raylet.pyx\", line 446, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 400, in ray._raylet.execute_task.function_executor\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/util/iter.py\", line 1125, in par_iter_next\n    return next(self.local_it)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 263, in gen_rollouts\n    yield self.sample()\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 528, in sample\n    batches = [self.input_reader.next()]\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 59, in next\n    batches = [self.get_data()]\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 164, in get_data\n    item = next(self.rollout_provider)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 489, in _env_runner\n    observation_fn=observation_fn)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 641, in _process_observations\n    policy_id).transform(raw_obs)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\", line 199, in transform\n    self.check_shape(observation)\n  File \"/home/incubator/anaconda3/envs/rsm-rl/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\", line 62, in check_shape\n    self._obs_space, observation)\nValueError: ('Observation outside expected value range', Tuple(Box(100, 100), Box(100, 60)), None)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
